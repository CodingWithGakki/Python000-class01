#--*--encoding:utf-8--*--
import requests
import lxml.etree
from time import sleep
import pandas as pd
import numpy as np
from snownlp import SnowNLP
import pymysql



class FilmComment():
    
    """
    获取电影短评信息
    """

    def __init__(self):
        pass

    def get_film_comment_text(url):

        user_agent = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 \(KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36"
        header = {}
        header['user-agent'] = user_agent
        response = requests.get(url, headers=header)
        selector = lxml.etree.HTML(response.text)

        film_comment_data = selector.xpath("//div[@class='mod-bd']/div")
        
        reviews_text = []
        for fcomment in film_comment_data:
            star = ''.join(fcomment.xpath(".//div[@class='comment']/descendant::span[@title]/@title"))
            shorts = ''.join(fcomment.xpath(".//span[@class='short']/text()"))
            reviews_text.append([star[:2], shorts])
        # print(reviews_text[0])
        return reviews_text

class DataMake(object):
    """
    #数据处理，标记情感分析
    """
    def __init__(self):
        pass


    def data_process(data):
        columns = ['star','shorts']
        df = pd.DataFrame(columns=columns,data=data)
        star_to_number = {
                        '力荐' : 5,
                        '推荐' : 4,
                        '还行' : 3,
                        '较差' : 2,
                        '很差' : 1
                        }
        df['new_star'] = df['star'].map(star_to_number)
        df['shorts'] = df['shorts'].str.split(',',expand=True).replace('',np.nan)
        df = df.dropna()
        def _sentiment(text):
            s = SnowNLP(text)
            return s.sentiments
        df["sentiment"] = df.shorts.apply(_sentiment)
        return df




class ConnDB(object):
    """
    访问Mysql数据库类
    """
    def __init__(self, dbInfo, sqls):
        self.host = dbInfo['host']
        self.port = dbInfo['port']
        self.user = dbInfo['user']
        self.password = dbInfo['password']
        self.db = dbInfo['db']
        self.sqls = sqls
        self.run()
    def run(self):
        conn = pymysql.connect(
            host = self.host,
            port = self.port,
            user = self.user,
            password = self.password,
            db = self.db
        )
        cur = conn.cursor()
        try:
            for command in self.sqls:
                cur.execute(command)
            cur.close()
            conn.commit()
        except Exception as e:
            conn.rollback()
            print(f'Error info: {e}')
        conn.close()
class SavetoDate(object):
    def __init__(self):
        pass
    def save_to_mysql(data):
        
        dbInfo = {
            'host' : 'localhost',
            'port' : 3306,
            'user' : 'root',
            'password' : 'rootroot',
            'db' : 'test'
        }
        create_table_sql = ["CREATE TABLE DoubanBook (new_star VARCHAR(10), shorts VARCHAR(2048), sentiment FLOAT)"]
        db = ConnDB(dbInfo, create_table_sql)
        sqls = []
        for index, row in data.iterrows() : 
            sqls.append(f'INSERT INTO DoubanBook (new_star,shorts,sentiment) VALUES ({row["new_star"]},"{row["shorts"]}",{row["sentiment"]})')

        db = ConnDB(dbInfo, sqls)
        return


if __name__ == '__main__':

    urls = tuple(f'https://movie.douban.com/subject/34461680/comments?start={page * 20}&limit=20&sort=new_score&status=P' for page in range(1))
    fs = FilmComment    
    for url in urls:
        s = fs.get_film_comment_text(url)
        if s:
            data += s
    fd = DataMake
    pd_data = fd.data_process(data)

    pp = SavetoDate
    pp.save_to_mysql(pd_data)
    

