学习笔记
本周的学习主要有三个部分，首先是NLP中的jieba库的使用，jieba库主要用来分词，分为精确模式和全模式，当然也可以自定义词库。针对一些干扰词太多，比如得了这种语气助词，可以设置停止词进行屏蔽。分词采用的是HMM隐马尔可夫算法，这种算法再自然语言处理中颇为常见。在关键词提取中，TF-IDF:一个文档频率如果很高，TF就很高，接着去查语料库，如果语料库却很少，DF就很少，IDF（DF倒数）就高。所以TF-IDF高则代表关联度高。在得到关键词之后，可以绘制词云来进行可视化处理。
此外，snowNLP模块除了能进行中文分词外，还可以进行词性标注，同时根据训练的模型可以做情感分析。pytorch是经典的torch库，通过预先训练好得词向量，能够进行推导。最后对flask有了一些基本的认识，flask与django比，是一个轻量级框架，在学习了快速上手后，更加确认了这一点，感觉不是专门做前端的工作，也需要了解一些这种轻量级框架，这样有助于可视化数据得输出。