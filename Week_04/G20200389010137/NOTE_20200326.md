# 协程

时间通知值港澳同行证

线程：抢占式

协程：非抢占式，yield 功能不完善的协程

现场：调度式的

协程：主动调度，人为谁给了 next 了就运行

## 迭代器

### 概念

```python
# 三个属性都有，是一个完备的迭代器
alist = [1, 2, 3, 4, 5]
hasattr( alist, '__iter__' )  # True
hasattr( alist, '__getitem__' )  # True
hasattr( alist, '__next__' )  # False

for i in alist：        # 实现了 iter 和 getitem 就可以 for in 了
    i

# 结论一  列表是可迭代对象，或称作可迭代（iterable）,
#         不是迭代器（iterator）
```

```python
g = ( i for i in range(5))
g  #<generator object>

hasattr( g, '__iter__' )  # True
hasattr( g, '__next__' )  # True

g.__next__()                    # 实现了 iter next 就可以next迭代了
next(g)
for i in g:
    i

# 结论二 生成器实现完整的迭代器协议
```

### 类实现迭代器

```python
# 类实现完整的迭代器协议

class SampleIterator:
    def __iter__(self):
        return self

    def __next__(self):
        # Not The End
        if ...:
            return ...
        # Reach The End
        else:
            raise StopIteration
```

### 函数实现迭代器

```python
# 函数实现完整的迭代器协议
def SampleGenerator():
    yield ...
    yield ...
    yield ...  # yield语句

# check iter
def check_iterator(obj):
    if hasattr( obj, '__iter__' ):
        if hasattr( obj, '__next__' ):
            print(f'{obj} is a iterator') # 完整迭代器协议
        else:
            print(f'{obj} is a iterable') # 可迭代对象
    else:
        print(f'{obj} can not iterable') # 不可迭代

def func1():
    yield range(5)

check_iterator(func1)
check_iterator(func1())

# 结论三： 有yield的函数是迭代器，执行yield语句之后才变成生成器构造函数
```

### 无限迭代器

```python
# itertools的三个常见无限迭代器
import itertools

count = itertools.count()  # 计数器
next(count)
next(count)
next(count)
```

```python
###############
cycle = itertools.cycle( ('yes', 'no') ) # 循环遍历
next(cycle)
next(cycle)
next(cycle)
```

```python
###############
repeat = itertools.repeat(10, times=2)  # 重复
next(repeat)
next(repeat)
next(repeat)
```

### 有限迭代器

```python
# 有限迭代器
for j in itertools.chain('ABC',[1, 2, 3]) :
    j

# Python3.3 引入了 yield from
21：24
1 是把后面的扁平
2 是 看后面的函数中是否还有 yield，会把后面 yield 的值返回
# PEP-380
def chain(*iterables):
    for it in iterables:        # 两层循环
        for i in it:
            yield i

s = 'ABC'
t = tuple(1, 2, 3)
list(chain(s, t))

def chain2(*iterables):
    for i in iterables:
        yield from i   # 替代内层循环，把上面两层循环变成一层循环

list(chain2(s, t))
```

### 迭代器有效性测试

1. 字典进行插入操作后，字典迭代器回立即失效，被破坏

    ```python
    # 迭代器有效性测试
    a_dict = {'a':1, 'b':2}
    a_dict_iter = iter(a_dict)

    next(a_dict_iter)

    a_dict['c']=3

    next(a_dict_iter)
    # RuntimeError: 字典进行插入操作后，字典迭代器回立即失效，被破坏
    ```

2. 尾插入操作不会损坏指向当前元素的List迭代器,列表会自动变长,迭代器只关心下标，不关心长度

3. 迭代器一旦耗尽，永久损坏

    ```python
    # 迭代器一旦耗尽，永久损坏
    x = iter([ y for y in range(5)])
    for i in x:
        i
    x.__next__()
    ```

## yield 表达式

可以传值进去，接收值，之前只能传出值

send(None) 就相当于 next，send(60)，就把 60 传给 yield ，yield 再把 60 赋值给 x (x = yield)，yield 后面的值是它传出的值

开 debug 分析

```python
def jumping_range(up_to):
    """
    Generator for the sequence of integers from 0 to up_to, exclusive.
    Sending a value into the generator will shift the sequence by that amount.
    """
    index = 0
    while index < up_to:
        jump = yield index      # jield 传出
        if jump is None:
            jump = 1   # next() 或者 send(None)
        index += jump

if __name__ == '__main__':
    iterator = jumping_range(5)
    print(next(iterator)) # 0
    print(iterator.send(2)) # 2     # 传入值
    print(next(iterator)) # 3
    print(iterator.send(-1)) # 2
    for x in iterator:
        print(x) # 3, 4
```

def func():
    x = yield 1         #
    y = yield 2
    z = yield 3

1. 执行 yield 1
2. 执行 x ，yield 2
3. 执行 y， yield 3
4. z

## yield from 表达式

yield from，后面再有 yield，能扁平化

```python
# Python3.3之后引入了新语法 yield from
def ex1():
    yield 1
    yield 2
    return 3

def ex2():
    ex1_result = yield from ex1()   # 执行函数，如果遇到 yield，也把它执行了
    print(f'ex1 : {ex1_result}')
    yield None

gen1 = ex1()
gen1.send(None) # 1
gen1.send(None) # 2
gen1.send(None) # send 执行到return 返回 StopIteration: 3

for i in ex2():
    print(i)
# 1
# 2
# ex1:3
# None
```

```python
##########################
def bottom():
# Returning the yield lets the value that goes up the call stack to come right back
# down.
    return (yield 42)

def middle():
    return (yield from bottom())

def top():
    return (yield from middle())

# Get the generator.
gen = top()
value = next(gen)
print(value) # Prints '42'.
try:
    value = gen.send(value * 2)
except StopIteration as exc:
    value = exc.value
print(value) # Prints '84'
```

## 3.5 的协程

已淘汰：

```python
# python3.4 支持事件循环的方法
import asyncio

def sth():
    pass

@asyncio.coroutine
def py34_func():
    yield from sth()
```

python3.5 增加 async 和 await：

```python
# async、await 必须一起出现，await 必须在函数中使用
async def py35_func():
    await sth()
```

注意： await 接收的对象必须是 awaitable 对象

awaitable 对象定义了__await__()方法

awaitable 对象有三类：

1. 协程 coroutine：单独一个协程
2. 任务 Task：一组协程组成一组任务
3. 未来对象 Future：底层 async、await 实现

coroutine：单独一个协程：

```python
import asyncio
async def main():
    print('hello')
    await asyncio.sleep(3)
    print('world')

# asyncio.run()运行最高层级的conroutine
asyncio.run(main())
# hello
# sleep 3 second
# world
```

task：

```python
# 协程调用过程：
# 调用协程时，会被注册到ioloop，返回coroutine对象
# 用ensure_future 封装为Future对象
# 提交给ioloop
import aiohttp
import asyncio
import time

# async 函数被调用后会创建一个coroutine
# 这时候该协程并不会立即运行，
# 需要通过 ensure_future 或 create_task 方法生成 Task 后才会被调度执行
async def mission(time):
    await asyncio.sleep(time)

async def main():
    start_time = time.time()
    # asyncio.create_task()封装成task，函数用来并发运行作为 asyncio 任务 的多个协程
    tasks = [asyncio.create_task(mission(1)) for proxy in range(10000)] # 10000个协程
    [await t for t in tasks]
    print(time.time() - start_time)

if __name__ == "__main__":
    asyncio.run(main())
```

Future：

```python
import asyncio
import time

async def coroutine_child1_demo():
    await asyncio.sleep(2)
    return 1
async def coroutine_child2_demo():
    await asyncio.sleep(5)
    return 2

tasks = [
    coroutine_child1_demo(),
    coroutine_child2_demo()
]

if __name__ == "__main__":
    start = time.time()  # 开始时间

    ioloop = asyncio.get_event_loop()  # 创建事件循环ioloop
    coroutine = asyncio.wait(tasks) # 启动协程
    # Future 是一种特殊的 低层级 可等待对象，表示一个异步操作的 最终结果
    future = asyncio.ensure_future(coroutine)   # 封装成一个future对象
    ioloop.run_until_complete(future) # 提交给ioloop,等future对象完成
    ioloop.close()   # 不进行ioloop读写要关闭

    #debug
    print(future.done())    # 协程任务是否完成
    print(future.result())  # 协程任务执行的结果

    end = time.time()  # 结束时间

    print(str(end-start))
```

建议阅读官方文档 <https://docs.python.org/zh-cn/3/library/asyncio-task.html>

## aiohttp

```python
import aiohttp
import asyncio

url = 'http://httpbin.org/get'

async def fetch(client, url):
    # get 方式请求url
    async with client.get(url) as resp:
        assert resp.status == 200
        return await resp.text()

async def main():
    # 获取session对象
    async with aiohttp.ClientSession() as client:
        html = await fetch(client, url)
        print(html)

loop = asyncio.get_event_loop()
task = loop.create_task(main())
loop.run_until_complete(task)
# Zero-sleep 让底层连接得到关闭的缓冲时间
loop.run_until_complete(asyncio.sleep(0))
loop.close()
```

```python
import aiohttp
import asyncio

urls = [
    'http://httpbin.org',
    'http://httpbin.org/get',
    'http://httpbin.org/ip',
    'http://httpbin.org/headers'
]

async def  crawler():
    async with aiohttp.ClientSession() as session:
        futures = map(asyncio.ensure_future, map(session.get, urls))
        for task in asyncio.as_completed(futures):
            print(await task)

if __name__ == "__main__":
    ioloop = asyncio.get_event_loop()
    ioloop.run_until_complete(asyncio.ensure_future(crawler()))
```

## 基于协程的 web 服务器

```python
# Web Server
from aiohttp import web

# views
async def index(request):
    return web.Response(text='hello aiohttp')

# routes
def setup_routes(app):
    app.router.add_get('/', index)

# app
app = web.Application()
setup_routes(app)
web.run_app(app, host='127.0.0.1', port=8080)
```

官方文档 <https://hubertroy.gitbooks.io/aiohttp-chinese-documentation/content/aiohttp%E6%96%87%E6%A1%A3/ServerTutorial.html>

## 进程池和协程

```python
from multiprocessing import Pool
import asyncio
import time


async def test(time):
    await asyncio.sleep(time)

async def main(num):
    start_time = time.time()
    tasks = [asyncio.create_task(test(1)) for proxy in range(num)]
    [await t for t in tasks]
    print(time.time() - start_time)


def run(num):
    asyncio.run(main(num))


if __name__ == "__main__":
    start_time = time.time()
    p = Pool()
    for i in range(4):
        p.apply_async(run, args=(2500,))
    p.close()
    p.join()
    print(f'total {time.time() - start_time}')
```
