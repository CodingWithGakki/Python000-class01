# Pandas

```python
from sklearn import datasets #引入数据集
# 鸢尾花数据集
iris=datasets.load_iris()
X, y=iris.data, iris.target

# 查看特征
iris.feature_names

# 查看标签
iris.target_names

# 按照3比1的比例划分训练集和测试集
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)


# load_xxx 各种数据集
# load_boston Boston房屋价格 回归
# load_digits 手写体  分类
# load_iris   鸢尾花 分类聚类
```

```python
import pandas as pd
import numpy as np
import matplotlib as plt

df = pd.read_csv('book_utf8.csv')
# 输出全部内容
print(df)

# 筛选一列 ？
df['还行']      # 用列头筛出列，列头默认是第一行的字段

# 切片方式筛选
# 显示前3行
df[1:3]

# 增加列名
df.columns = ['star', 'vote', 'shorts']

# 显示特定的行、列
df.loc[1:3, ['star']]

# 过滤数据
df['star'] == '力荐'
df [ df['star'] == '力荐' ]     # 取力荐这一行

# 缺失数据
df.dropna()         # 删除缺失数据


# 数据聚合
df.groupby('star').sum()    # 分组求和
df.groupby('star').count()  # 分组求个数

# 创建新列
star_to_number = {
    '力荐' : 5,
    '推荐' : 4,
    '还行' : 3,
    '较差' : 2,
    '很差' : 1
}
df['new_star'] = df['star'].map(star_to_number)
```

## Series

单列数据，当作一列（或当作一行），底层是 numpy，自动建立索引

pd 取一行或一列的时候，会自动转成 Series

```python
import pandas as pd
import numpy as np

# 从列表创建Series
pd.Series(['a', 'b', 'c'])
# 0    a
# 1    b
# 2    c
# dtype: object
# 自动创建索引

# 通过字典创建带索引的Series
s1 = pd.Series({'a':11, 'b':22, 'c':33})

# 通过关键字创建带索引的Series
s2 = pd.Series([11, 22, 33], index = ['a', 'b', 'c'])

s1
s2

# 获取全部索引
s1.index
# 获取全部值
s1.values

# 类型
type(s1.values)    # <class 'numpy.ndarray'>
type(np.array(['a', 'b']))

# 转换为列表
s1.values.tolist()

# 使用index会提升查询性能
#    如果index唯一，pandas会使用哈希表优化，查询性能为O(1)
#    如果index有序不唯一，pandas会使用二分查找算法，查询性能为O(logN)
#    如果index完全随机，每次查询都要扫全表，查询性能为O(N)

# 取出email
emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])
import re
pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,4}'
mask = emails.map(lambda x: bool(re.match(pattern, x)))
emails[mask]
```

## DataFrame

```python
import pandas as pd


# 列表创建dataframe
df1 = pd.DataFrame(['a', 'b', 'c', 'd'])
# 嵌套列表创建dataframe
df2 = pd.DataFrame([
                     ['a', 'b'],
                     ['c', 'd']
                    ])
# 自定义列索引
df2.columns= ['one', 'two']
# 自定义行索引
df2.index = ['first', 'second']

df2
# 可以在创建时直接指定 DataFrame([...] , columns='...', index='...' )
# 查看索引
df2.columns, df2.index
type(df2.values)
```

## 导入外部数据

导入 excle：

```python
import pandas as pd
# pip install xlrd
# 导入excel文件
excel1 = pd.read_excel(r'0321.xlsx')
excel1
# 指定导入哪个Sheet
pd.read_excel(r'0321.xlsx', sheet_name=0)

# 指定第2行做列索引
# head参数值默认为0，即用第一行作为列索引
pd.read_excel(r'0321.xlsx', head=1)

# 熟悉数据
# 显示前几行
excel1.head(3)

# 行列数量
excel1.shape
```

从 csv 导入数据：

```python
pd.read_csv(r'c:\file.csv', sep=' ', nrow=10, encoding='utf-8')
```

从 txt 导入数据：

```python
pd.read_table( r'file.txt', sep = ' ')
```

从 mysql 导入数据：

```python
import pymysql
sql  =  'SELECT *  FROM mytable'
conn = pymysql.connect('ip','name','pass','dbname','charset=utf8')
df = pd.read_sql(sql,conn)


# 详细信息
df.info()
df.describe()
```

pickle会比 excle 快 7 倍。

## 预处理缺失值

```python
import pandas as pd

x = pd.Series([ 1, 2, np.nan, 3, 4, 5, 6,np.nan, 8])
#检验序列中是否存在缺失值
x.hasnans

# 将缺失值填充为平均值
x.fillna(value = x.mean())

# 前向填充缺失值

df3=pd.DataFrame({"A":[5,3,None,4],
                 "B":[None,2,4,3],
                 "C":[4,3,8,5],
                 "D":[5,4,2,None]})
df3.isnull().sum()         # 查看缺失值汇总
df3.ffill()                 # 前一行，用它头顶上的值填充
df3.ffill(axis=1)           # 前一列，用它左边的值填充
df3.ffill(axis=1).ffill()    # 前一列，用它左边的值填充

# 缺失值删除
excel1 = pd.read_excel(r'0321.xlsx')
excel1.info()
excel1.dropna()

# 填充缺失值
excel1.fillna('无')

# 重复值处理
excel1.drop_duplicates()

# 重新设置行索引
df.set_index=['new_star']
```

## 数据分割

```python
# 列的选择,多个列要用列表
df[ ['star', 'new_star'] ]

# 某几列
df.iloc[:, [0,2]] # :表示所有行，获得第1和第3列

# 行选择
df.loc[ [0, 2] ] # 选择第1行和第3行
df.loc[ 0:2    ] # 选择第1行到第3行

# 比较
df[ ( df['年龄']<30 ) & ( df['员工id']<100 )   ]


# 数值替换

# 一对一替换
# 用于单个异常值处理
df['年龄'].replace(240, 37)

df.replace(np.NaN, 0)

# 多对一替换
df.replace([100,200,300], 1000)

# 多对多替换
df.replace({100:10, 200:20, 300:30})



# 排序
# 按照指定列降序排列
df.sort_values(by=['new_star'], ascending=False)

# 多列排序
df.sort_values(by=['col1','col2'], ascending=[True,False])


# 删除
# 删除列
df.drop(df.columns['a', 'b'], axis=1)

# 删除行
df.drop(['a', 'b'], axis =0)

# 删除特定行
df [df['年龄'] < 40]


# 行列互换
df.T
df.T.T

# 索引重塑，数据透视表
df2 = pd.DataFrame([
                     ['a', 'b', 'c'],
                     ['d', 'e', 'f']
                    ],
                    columns= ['one', 'two', 'three'],
                    index = ['first', 'second']
                   )
df2.stack()
df2.unstack()
df2.stack().reset_index()
```

## 操作

```python
import pandas as pd

# 算数运行
# 两列之间的加减乘除
df['num1'] + df['num2']

# 任意一列加/减一个常数值，这一列中的所有值都加/减这个常数值
df['num1'] + 5

# 比较运算
df['num1'] > df ['num2']

# count非空值计数
excel1 = pd.read_excel(r'0321.xlsx')
excel1.count()
excel1.sum()
df['new_star'].sum()

# mean求均值
# max求最大值
# min求最小值
# median求中位数
# mode求众数
# var求方差
# std求标准差
```

## 多表连接

表横向连接，两个表有公共的列

```python
import pandas as pd
import numpy as np

group = ['x','y','z']
data1 = pd.DataFrame({
    "group":[group[x] for x in np.random.randint(0,len(group),10)] ,
    "age":np.random.randint(15,50,10)
    })

data2 = pd.DataFrame({
    "group":[group[x] for x in np.random.randint(0,len(group),10)] ,
    "salary":np.random.randint(5,50,10),
    })

data3 = pd.DataFrame({
    "group":[group[x] for x in np.random.randint(0,len(group),10)] ,
    "age":np.random.randint(15,50,10),
    "salary":np.random.randint(5,50,10),
    })

# 一对一
pd.merge(data1, data2)

# 多对一
pd.merge(data3, data2, on='group')

# 多对多
pd.merge(data3, data2)

# 连接键类型，解决没有公共列问题
pd.merge(data3, data2, left_on='a', right_on='b')   # a 列，b 列

pd.merge(data3, data2, left_index='a', right_index='b')     # 索引

# 连接方式
# 内连接，不指明连接方式，默认都是内连接
pd.merge(data3, data2, on='group', how='inner') # on 连接键，how 连接方法
# 左连接 left
# 右连接 right
# 外连接 outer

# 纵向拼接，两个表列名必须完全相同
pd.concat([data1, data2])
```

## 分组聚合

```python
# 聚合
sales = [{'account': 'Jones LLC', 'type':'a', 'Jan': 150, 'Feb': 200, 'Mar': 140},
         {'account': 'Alpha Co', 'type':'b',  'Jan': 200, 'Feb': 210, 'Mar': 215},
         {'account': 'Blue Inc', 'type':'a',  'Jan': 50,  'Feb': 90,  'Mar': 95 }]

df2 = pd.DataFrame(sales)
# 聚合后再计算
df2.groupby('type').count()
df2.groupby('Jan').sum()

df2.groupby('type').aggregate( {'type':'count' , 'Feb':'sum' })  # aggregate 可缩写为 agg
```

```python
import pandas as pd
import numpy as np

group=['x','y','z']
data=pd.DataFrame({
    "group":[group[x] for x in np.random.randint(0,len(group),10)] ,
    "salary":np.random.randint(5,50,10),
    "age":np.random.randint(15,50,10)
    })


data.groupby('group').agg('mean')
data.groupby('group').mean().to_dict()
data.groupby('group').transform('mean')     # 也是取平均值，然后写入到每个值上面
```

```python
# 数据透视表
# 行列同时做拆分
data=pd.DataFrame({
    "group":[group[x] for x in np.random.randint(0,len(group),10)] ,
    "salary":np.random.randint(5,50,10),
    "age":np.random.randint(15,50,10)
    })

pd.pivot_table(data,
               values='salary',
               columns='group',
               index='age',
               aggfunc='count',
               margins=True
            ).reset_index()
```

## 输出

```python
# 导出为.xlsx文件
df.to_excel( excel_writer = r'file.xlsx')

# 设置Sheet名称
df.to_excel( excel_writer = r'file.xlsx', sheet_name = 'sheet1')

# 设置索引,设置参数index=False就可以在导出时把这种索引去掉
df.to_excel( excel_writer = r'file.xlsx', sheet_name = 'sheet1', index =False)

# 设置要导出的列
df.to_excel( excel_writer = r'file.xlsx', sheet_name = 'sheet1',
             index =False, columns = ['col1','col2'])

# 设置编码格式
enconding = 'utf-8'

# 缺失值处理
na_rep = 0 # 缺失值填充为0

# 无穷值处理
inf_rep = 0

# 导出为.csv文件
to_csv()

# 性能比 csv 高
df.to_pickle('xx.pkl')

agg(sum)                # 快
agg(lambda x: x.sum())  # 慢
```

## 展示

import matplotlib.pyplot as plt
plt.plot(df.index, df['A'], )
plt.show()

plt.plot(df.index, df['A'])

import seaborn

## 扩展

把 pandas 转化为 python 进行相应的处理，用到下面的魔术方法

to_list()

类
__str__：字符串
__getitem__、__setitem__、__delitem__：字典
__iter__：迭代器
__call__:
__eq__、__gt__、__ge__ 。。。。：比较
__add__、__sub__：加减
__hash__：用类做字典
