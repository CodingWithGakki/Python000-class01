2020-03-23 17:05:09 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:05:09 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:05:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:05:09 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like '
               'Gecko) Chrome/19.0.1061.0 Safari/536.3'}
2020-03-23 17:05:09 [scrapy.extensions.telnet] INFO: Telnet Password: 6280e5c0967bf415
2020-03-23 17:05:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:05:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:05:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:05:10 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:05:10 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:05:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:05:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:05:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.rrys2019.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: www.rrys2019.com.
2020-03-23 17:05:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:05:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:05:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/10945>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '本站排名:\xa0\xa058  ',
 'viewCount': []}
2020-03-23 17:05:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:05:24 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '本站排名:\xa0\xa03770  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:05:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:05:25 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '本站排名:\xa0\xa02304  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:05:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:05:26 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '本站排名:\xa0\xa073  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:05:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:05:27 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '本站排名:109  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:05:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:05:29 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '本站排名:\xa0\xa026  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:05:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:05:30 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '本站排名:\xa0\xa07  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:05:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:05:32 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '本站排名:\xa0\xa02245  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:05:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:05:33 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '本站排名:7470  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:05:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:05:34 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '本站排名:\xa0\xa04133  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:05:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:05:36 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '本站排名:9794  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:05:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:05:36 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '本站排名:\xa0\xa09  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:05:36 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:05:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 1,
 'downloader/request_bytes': 4496,
 'downloader/request_count': 14,
 'downloader/request_method_count/GET': 14,
 'downloader/response_bytes': 146373,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 26.771547,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 5, 36, 889828),
 'item_scraped_count': 1,
 'log_count/DEBUG': 15,
 'log_count/ERROR': 11,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'retry/count': 1,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 1,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2020, 3, 23, 9, 5, 10, 118281)}
2020-03-23 17:05:36 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:16:28 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:16:28 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:16:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:16:28 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/66.0.3359.139 '
               'Safari/537.36Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 '
               '(KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3'}
2020-03-23 17:16:28 [scrapy.extensions.telnet] INFO: Telnet Password: dbe151775f66ad5f
2020-03-23 17:16:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:16:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:16:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:16:28 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:16:28 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:16:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:16:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:16:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:16:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:16:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/33701>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa09  ',
 'viewCount': []}
2020-03-23 17:16:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:16:30 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa058  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:16:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:16:32 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa03770  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:16:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:16:33 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa02304  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:16:34 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa073  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:16:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:16:35 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '109  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:16:37 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '\xa0\xa026  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:16:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:16:38 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa07  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:16:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:16:39 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '\xa0\xa02245  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:16:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:16:40 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7470  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:16:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:16:42 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa04133  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:16:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:16:43 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9794  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:16:43 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:16:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5646,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 145891,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 15.149704,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 16, 43, 535490),
 'item_scraped_count': 1,
 'log_count/DEBUG': 14,
 'log_count/ERROR': 11,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2020, 3, 23, 9, 16, 28, 385786)}
2020-03-23 17:16:43 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:17:30 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:17:30 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:17:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:17:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 5,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, '
               'like Gecko) Chrome/19.0.1055.1 Safari/535.24'}
2020-03-23 17:17:30 [scrapy.extensions.telnet] INFO: Telnet Password: b1ad15f2b43b0a32
2020-03-23 17:17:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:17:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:17:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:17:30 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:17:30 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:17:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:17:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:17:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:17:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:17:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39705>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '109  ',
 'viewCount': []}
2020-03-23 17:17:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:17:40 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '\xa0\xa026  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:17:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:17:43 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa07  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:17:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:17:49 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '\xa0\xa02245  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:17:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:17:56 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7470  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:18:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:18:03 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa04133  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:18:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:18:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:18:12 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9794  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:18:12 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa09  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:18:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:18:19 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa058  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:18:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:18:26 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa03770  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:18:30 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 11 pages/min), scraped 1 items (at 1 items/min)
2020-03-23 17:18:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:18:31 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa02304  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:18:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:18:38 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa073  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:18:38 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:18:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4281,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 145948,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 67.992268,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 18, 38, 409571),
 'item_scraped_count': 1,
 'log_count/DEBUG': 14,
 'log_count/ERROR': 11,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2020, 3, 23, 9, 17, 30, 417303)}
2020-03-23 17:18:38 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:21:29 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:21:29 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:21:29 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:21:29 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, '
               'like Gecko) Chrome/19.0.1055.1 Safari/535.24'}
2020-03-23 17:21:29 [scrapy.extensions.telnet] INFO: Telnet Password: 4c2f06e93af42069
2020-03-23 17:21:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:21:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:21:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:21:29 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:21:29 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:21:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:21:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:21:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:21:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:21:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/10945>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa058  ',
 'viewCount': <Element label at 0x1e77bd38b80>}
2020-03-23 17:21:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:21:36 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '109  ',
 'viewCount': <Element label at 0x1e77bd45440>}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:21:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:21:37 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa02304  ',
 'viewCount': <Element label at 0x1e77bd0b240>}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:21:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:21:38 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '\xa0\xa026  ',
 'viewCount': <Element label at 0x1e77bd08ac0>}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:21:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:21:38 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa073  ',
 'viewCount': <Element label at 0x1e77bd38d80>}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:21:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:21:38 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa03770  ',
 'viewCount': <Element label at 0x1e77bd21440>}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:21:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:21:38 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa07  ',
 'viewCount': <Element label at 0x1e77bcdd0c0>}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:21:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:21:40 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '\xa0\xa02245  ',
 'viewCount': <Element label at 0x1e77bd38b80>}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:21:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:21:41 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7470  ',
 'viewCount': <Element label at 0x1e77bd21180>}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:21:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:21:42 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa04133  ',
 'viewCount': <Element label at 0x1e77bb8a9c0>}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:21:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:21:43 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9794  ',
 'viewCount': <Element label at 0x1e77bd01c00>}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:21:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:21:45 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa09  ',
 'viewCount': <Element label at 0x1e77bd21640>}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:21:45 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:21:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4281,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 145948,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 15.1634,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 21, 45, 143451),
 'item_scraped_count': 1,
 'log_count/DEBUG': 14,
 'log_count/ERROR': 11,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2020, 3, 23, 9, 21, 29, 980051)}
2020-03-23 17:21:45 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:26:09 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:26:09 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:26:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:26:09 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, '
               'like Gecko) Chrome/19.0.1061.1 Safari/536.3'}
2020-03-23 17:26:09 [scrapy.extensions.telnet] INFO: Telnet Password: 1c445d726cc2ffc4
2020-03-23 17:26:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:26:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:26:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:26:09 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:26:09 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:26:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:26:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:26:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:26:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:26:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39662>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9794  ',
 'viewCount': ''}
2020-03-23 17:26:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:26:12 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa09  ',
 'viewCount': ''}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:26:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:26:13 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa058  ',
 'viewCount': ''}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:26:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:26:15 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa03770  ',
 'viewCount': ''}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:26:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:26:16 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa02304  ',
 'viewCount': ''}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:26:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:26:17 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa073  ',
 'viewCount': ''}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:26:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:26:18 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '109  ',
 'viewCount': ''}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:26:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:26:19 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '\xa0\xa026  ',
 'viewCount': ''}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:26:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:26:21 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa07  ',
 'viewCount': ''}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:26:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:26:22 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '\xa0\xa02245  ',
 'viewCount': ''}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:26:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:26:22 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7470  ',
 'viewCount': ''}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:26:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:26:24 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa04133  ',
 'viewCount': ''}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:26:24 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:26:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4307,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 146433,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 14.618148,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 26, 24, 217366),
 'item_scraped_count': 1,
 'log_count/DEBUG': 14,
 'log_count/ERROR': 11,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2020, 3, 23, 9, 26, 9, 599218)}
2020-03-23 17:26:24 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:27:58 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:27:58 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:27:58 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:27:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like '
               'Gecko) Chrome/19.0.1061.1 Safari/536.3'}
2020-03-23 17:27:58 [scrapy.extensions.telnet] INFO: Telnet Password: db575150efcdd9e6
2020-03-23 17:27:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:27:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:27:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:27:58 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:27:58 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:27:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:27:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:27:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:27:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:27:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:28:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:28:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:28:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:28:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:28:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:28:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:28:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:28:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:28:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:28:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:28:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:13 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:28:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4216,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 146433,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 14.906242,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 28, 13, 253339),
 'log_count/DEBUG': 13,
 'log_count/ERROR': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'spider_exceptions/IndexError': 12,
 'start_time': datetime.datetime(2020, 3, 23, 9, 27, 58, 347097)}
2020-03-23 17:28:13 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:28:25 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:28:25 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:28:25 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:28:25 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like '
               'Gecko) Chrome/19.0.1061.1 Safari/536.3'}
2020-03-23 17:28:25 [scrapy.extensions.telnet] INFO: Telnet Password: 3ef0a435bc98797f
2020-03-23 17:28:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:28:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:28:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:28:25 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:28:25 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:28:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:28:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:28:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:28:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:28:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:28:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:28:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:28:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:28:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:28:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:28:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:28:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:28:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:28:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:28:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:41 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:28:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4216,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 146433,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 16.386543,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 28, 41, 658837),
 'log_count/DEBUG': 13,
 'log_count/ERROR': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'spider_exceptions/IndexError': 12,
 'start_time': datetime.datetime(2020, 3, 23, 9, 28, 25, 272294)}
2020-03-23 17:28:41 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:28:55 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:28:55 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:28:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:28:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like '
               'Gecko) Chrome/19.0.1061.1 Safari/536.3'}
2020-03-23 17:28:55 [scrapy.extensions.telnet] INFO: Telnet Password: e7a062a9955d354b
2020-03-23 17:28:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:28:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:28:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:28:55 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:28:55 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:28:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:28:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:28:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:28:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:28:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:28:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:28:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:28:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:29:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:29:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:29:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:29:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:29:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:29:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:29:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:29:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:29:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:29:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:29:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:29:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:29:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:29:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:29:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:29:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:29:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:29:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 36, in parse2
    viewCount = selector.xpath(
IndexError: list index out of range
2020-03-23 17:29:10 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:29:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4216,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 146433,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 14.974579,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 29, 10, 851650),
 'log_count/DEBUG': 13,
 'log_count/ERROR': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'spider_exceptions/IndexError': 12,
 'start_time': datetime.datetime(2020, 3, 23, 9, 28, 55, 877071)}
2020-03-23 17:29:10 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:29:43 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:29:43 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:29:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:29:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/66.0.3359.139 '
               'Safari/537.36Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 '
               '(KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3'}
2020-03-23 17:29:43 [scrapy.extensions.telnet] INFO: Telnet Password: 23bbaedfe41055e8
2020-03-23 17:29:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:29:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:29:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:29:43 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:29:43 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:29:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:29:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:29:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:29:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:29:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/10945>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa058  ',
 'viewCount': []}
2020-03-23 17:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:29:46 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa03770  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:29:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:29:48 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa02304  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:29:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:29:49 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa073  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:29:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:29:50 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '109  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:29:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:29:51 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '\xa0\xa026  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:29:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:29:53 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa07  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:29:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:29:54 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '\xa0\xa02245  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:29:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:29:55 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7470  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:29:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:29:56 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa04133  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:29:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:29:57 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9794  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:29:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:29:58 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa09  ',
 'viewCount': []}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 18, in process_item
    self.move.write(output)
ValueError: I/O operation on closed file.
2020-03-23 17:29:58 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:29:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5646,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 146433,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 14.972672,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 29, 58, 965814),
 'item_scraped_count': 1,
 'log_count/DEBUG': 14,
 'log_count/ERROR': 11,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2020, 3, 23, 9, 29, 43, 993142)}
2020-03-23 17:29:58 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:34:38 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:34:38 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:34:38 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:34:38 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, '
               'like Gecko) Chrome/19.0.1062.0 Safari/536.3'}
2020-03-23 17:34:38 [scrapy.extensions.telnet] INFO: Telnet Password: 3985586b0c6946ae
2020-03-23 17:34:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:34:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:34:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:34:38 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:34:38 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:34:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:34:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:34:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:34:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:34:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37366>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa073  ',
 'viewCount': []}
2020-03-23 17:34:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:34:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39705>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '109  ',
 'viewCount': []}
2020-03-23 17:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:34:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11088>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '\xa0\xa026  ',
 'viewCount': []}
2020-03-23 17:34:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:34:43 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11057>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa07  ',
 'viewCount': []}
2020-03-23 17:34:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:34:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39654>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '\xa0\xa02245  ',
 'viewCount': []}
2020-03-23 17:34:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:34:46 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39693>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7470  ',
 'viewCount': []}
2020-03-23 17:34:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:34:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39526>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '\xa0\xa04133  ',
 'viewCount': []}
2020-03-23 17:34:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:34:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39662>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9794  ',
 'viewCount': []}
2020-03-23 17:34:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:34:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/33701>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa09  ',
 'viewCount': []}
2020-03-23 17:34:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:34:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/10945>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa058  ',
 'viewCount': []}
2020-03-23 17:34:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:34:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39628>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa03770  ',
 'viewCount': []}
2020-03-23 17:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:34:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37435>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '\xa0\xa02304  ',
 'viewCount': []}
2020-03-23 17:34:53 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:34:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4307,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 145948,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 14.251414,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 34, 53, 16286),
 'item_scraped_count': 12,
 'log_count/DEBUG': 25,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2020, 3, 23, 9, 34, 38, 764872)}
2020-03-23 17:34:53 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:35:56 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:35:56 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:35:56 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:35:56 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, '
               'like Gecko) Chrome/19.0.1055.1 Safari/535.24'}
2020-03-23 17:35:56 [scrapy.extensions.telnet] INFO: Telnet Password: 15ffd91de57cb978
2020-03-23 17:35:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:35:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:35:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:35:57 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:35:57 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:35:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:35:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:35:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:35:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:35:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 28, in parse2
    score = selector.xpath(
AttributeError: 'list' object has no attribute 'extract_first'
2020-03-23 17:36:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:36:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 28, in parse2
    score = selector.xpath(
AttributeError: 'list' object has no attribute 'extract_first'
2020-03-23 17:36:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:36:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 28, in parse2
    score = selector.xpath(
AttributeError: 'list' object has no attribute 'extract_first'
2020-03-23 17:36:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:36:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 28, in parse2
    score = selector.xpath(
AttributeError: 'list' object has no attribute 'extract_first'
2020-03-23 17:36:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:36:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 28, in parse2
    score = selector.xpath(
AttributeError: 'list' object has no attribute 'extract_first'
2020-03-23 17:36:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:36:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 28, in parse2
    score = selector.xpath(
AttributeError: 'list' object has no attribute 'extract_first'
2020-03-23 17:36:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:36:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 28, in parse2
    score = selector.xpath(
AttributeError: 'list' object has no attribute 'extract_first'
2020-03-23 17:36:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:36:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 28, in parse2
    score = selector.xpath(
AttributeError: 'list' object has no attribute 'extract_first'
2020-03-23 17:36:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:36:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 28, in parse2
    score = selector.xpath(
AttributeError: 'list' object has no attribute 'extract_first'
2020-03-23 17:36:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:36:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 28, in parse2
    score = selector.xpath(
AttributeError: 'list' object has no attribute 'extract_first'
2020-03-23 17:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:36:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 28, in parse2
    score = selector.xpath(
AttributeError: 'list' object has no attribute 'extract_first'
2020-03-23 17:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:36:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 28, in parse2
    score = selector.xpath(
AttributeError: 'list' object has no attribute 'extract_first'
2020-03-23 17:36:12 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:36:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4281,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 145948,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 15.415844,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 36, 12, 440678),
 'log_count/DEBUG': 13,
 'log_count/ERROR': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'spider_exceptions/AttributeError': 12,
 'start_time': datetime.datetime(2020, 3, 23, 9, 35, 57, 24834)}
2020-03-23 17:36:12 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:37:44 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:37:44 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:37:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:37:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, '
               'like Gecko) Chrome/19.0.1062.0 Safari/536.3'}
2020-03-23 17:37:44 [scrapy.extensions.telnet] INFO: Telnet Password: ac5e4e88ec026e59
2020-03-23 17:37:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:37:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:37:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:37:44 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:37:44 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:37:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:37:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:37:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:37:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/10945>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '58',
 'viewCount': []}
2020-03-23 17:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:37:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39628>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '3770',
 'viewCount': []}
2020-03-23 17:37:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37435>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '2304',
 'viewCount': []}
2020-03-23 17:37:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37366>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '73',
 'viewCount': []}
2020-03-23 17:37:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39705>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '109',
 'viewCount': []}
2020-03-23 17:37:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11088>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '26',
 'viewCount': []}
2020-03-23 17:37:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11057>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '7',
 'viewCount': []}
2020-03-23 17:37:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:37:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39654>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '2245',
 'viewCount': []}
2020-03-23 17:37:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:37:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39526>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '4133',
 'viewCount': []}
2020-03-23 17:37:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:37:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39693>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7470',
 'viewCount': []}
2020-03-23 17:37:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:37:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39662>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9794',
 'viewCount': []}
2020-03-23 17:37:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:37:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/33701>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '9',
 'viewCount': []}
2020-03-23 17:37:59 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:37:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4307,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 145902,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 15.328285,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 37, 59, 627862),
 'item_scraped_count': 12,
 'log_count/DEBUG': 25,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2020, 3, 23, 9, 37, 44, 299577)}
2020-03-23 17:37:59 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:38:26 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:38:26 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:38:26 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:38:26 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like '
               'Gecko) Chrome/19.0.1061.1 Safari/536.3'}
2020-03-23 17:38:26 [scrapy.extensions.telnet] INFO: Telnet Password: 52223f07ebffc21e
2020-03-23 17:38:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:38:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:38:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:38:27 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:38:27 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:38:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:38:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:38:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:38:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:38:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/10945>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '58',
 'viewCount': []}
2020-03-23 17:38:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:38:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39628>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '3770',
 'viewCount': []}
2020-03-23 17:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:38:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37435>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '2304',
 'viewCount': []}
2020-03-23 17:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:38:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37366>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '73',
 'viewCount': []}
2020-03-23 17:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:38:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39705>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '109',
 'viewCount': []}
2020-03-23 17:38:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:38:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39654>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '2245',
 'viewCount': []}
2020-03-23 17:38:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:38:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39662>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9794',
 'viewCount': []}
2020-03-23 17:38:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:38:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39526>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '4133',
 'viewCount': []}
2020-03-23 17:38:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:38:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11088>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '26',
 'viewCount': []}
2020-03-23 17:38:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:38:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/33701>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '9',
 'viewCount': []}
2020-03-23 17:38:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:38:43 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39693>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7470',
 'viewCount': []}
2020-03-23 17:38:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:38:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11057>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '7',
 'viewCount': []}
2020-03-23 17:38:45 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:38:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4216,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 145902,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 18.508666,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 38, 45, 603040),
 'item_scraped_count': 12,
 'log_count/DEBUG': 25,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2020, 3, 23, 9, 38, 27, 94374)}
2020-03-23 17:38:45 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:39:31 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:39:31 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:39:31 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:39:31 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)'}
2020-03-23 17:39:31 [scrapy.extensions.telnet] INFO: Telnet Password: 8d133a98be8617ca
2020-03-23 17:39:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:39:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:39:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:39:32 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:39:32 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:39:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:39:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:39:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:39:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:39:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/10945>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '本站排名:\xa0\xa058',
 'viewCount': []}
2020-03-23 17:39:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:39:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39705>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '本站排名:109',
 'viewCount': []}
2020-03-23 17:39:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:39:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37435>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '本站排名:\xa0\xa02304',
 'viewCount': []}
2020-03-23 17:39:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:39:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11088>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '本站排名:\xa0\xa026',
 'viewCount': []}
2020-03-23 17:39:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:39:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39628>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '本站排名:\xa0\xa03770',
 'viewCount': []}
2020-03-23 17:39:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:39:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:39:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11057>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '本站排名:\xa0\xa07',
 'viewCount': []}
2020-03-23 17:39:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37366>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '本站排名:\xa0\xa073',
 'viewCount': []}
2020-03-23 17:39:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:39:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39654>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '本站排名:\xa0\xa02245',
 'viewCount': []}
2020-03-23 17:39:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:39:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39526>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '本站排名:\xa0\xa04133',
 'viewCount': []}
2020-03-23 17:39:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:39:43 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39693>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '本站排名:7470',
 'viewCount': []}
2020-03-23 17:39:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:39:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39662>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '本站排名:9794',
 'viewCount': []}
2020-03-23 17:39:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:39:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/33701>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '本站排名:\xa0\xa09',
 'viewCount': []}
2020-03-23 17:39:45 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:39:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3683,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 145902,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 13.76717,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 39, 45, 874632),
 'item_scraped_count': 12,
 'log_count/DEBUG': 25,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2020, 3, 23, 9, 39, 32, 107462)}
2020-03-23 17:39:45 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:40:19 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:40:19 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:40:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:40:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, '
               'like Gecko) Chrome/19.0.1061.1 Safari/536.3'}
2020-03-23 17:40:19 [scrapy.extensions.telnet] INFO: Telnet Password: 9f71a4e54e37ee4a
2020-03-23 17:40:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:40:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:40:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:40:19 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:40:19 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:40:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:40:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:40:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:40:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:40:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/10945>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': ':\xa0\xa058',
 'viewCount': []}
2020-03-23 17:40:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:40:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39628>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': ':\xa0\xa03770',
 'viewCount': []}
2020-03-23 17:40:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:40:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37435>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': ':\xa0\xa02304',
 'viewCount': []}
2020-03-23 17:40:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:40:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37366>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': ':\xa0\xa073',
 'viewCount': []}
2020-03-23 17:40:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:40:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39705>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': ':109',
 'viewCount': []}
2020-03-23 17:40:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:40:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11088>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': ':\xa0\xa026',
 'viewCount': []}
2020-03-23 17:40:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:40:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11057>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': ':\xa0\xa07',
 'viewCount': []}
2020-03-23 17:40:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:40:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39654>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': ':\xa0\xa02245',
 'viewCount': []}
2020-03-23 17:40:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:40:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39526>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': ':\xa0\xa04133',
 'viewCount': []}
2020-03-23 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:40:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39693>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': ':7470',
 'viewCount': []}
2020-03-23 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:40:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39662>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': ':9794',
 'viewCount': []}
2020-03-23 17:40:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:40:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/33701>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': ':\xa0\xa09',
 'viewCount': []}
2020-03-23 17:40:42 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:40:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4307,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 145902,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 23.037468,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 40, 42, 437857),
 'item_scraped_count': 12,
 'log_count/DEBUG': 25,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2020, 3, 23, 9, 40, 19, 400389)}
2020-03-23 17:40:42 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:41:04 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:41:04 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:41:04 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:41:04 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/66.0.3359.139 '
               'Safari/537.36Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 '
               '(KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3'}
2020-03-23 17:41:04 [scrapy.extensions.telnet] INFO: Telnet Password: fb1445610b750463
2020-03-23 17:41:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:41:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:41:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:41:04 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:41:04 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:41:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:41:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:41:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:41:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:41:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/10945>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '本站排名:\xa0\xa058',
 'viewCount': []}
2020-03-23 17:41:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:41:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39628>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '本站排名:\xa0\xa03770',
 'viewCount': []}
2020-03-23 17:41:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:41:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37435>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '本站排名:\xa0\xa02304',
 'viewCount': []}
2020-03-23 17:41:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:41:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37366>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '本站排名:\xa0\xa073',
 'viewCount': []}
2020-03-23 17:41:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:41:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39705>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '本站排名:109',
 'viewCount': []}
2020-03-23 17:41:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:41:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11088>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '本站排名:\xa0\xa026',
 'viewCount': []}
2020-03-23 17:41:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:41:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11057>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '本站排名:\xa0\xa07',
 'viewCount': []}
2020-03-23 17:41:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:41:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39654>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '本站排名:\xa0\xa02245',
 'viewCount': []}
2020-03-23 17:41:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:41:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39526>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '本站排名:\xa0\xa04133',
 'viewCount': []}
2020-03-23 17:41:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:41:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39693>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '本站排名:7470',
 'viewCount': []}
2020-03-23 17:41:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:41:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39662>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '本站排名:9794',
 'viewCount': []}
2020-03-23 17:41:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:41:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/33701>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '本站排名:\xa0\xa09',
 'viewCount': []}
2020-03-23 17:41:19 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:41:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5646,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 145902,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 14.479978,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 41, 19, 258768),
 'item_scraped_count': 12,
 'log_count/DEBUG': 25,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2020, 3, 23, 9, 41, 4, 778790)}
2020-03-23 17:41:19 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:41:40 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:41:40 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:41:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:41:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/66.0.3359.139 '
               'Safari/537.36Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 '
               '(KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3'}
2020-03-23 17:41:40 [scrapy.extensions.telnet] INFO: Telnet Password: 0eb79b7f8c815d78
2020-03-23 17:41:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:41:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:41:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:41:40 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:41:40 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:41:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:41:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:41:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:41:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:41:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/10945>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '58',
 'viewCount': []}
2020-03-23 17:41:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:41:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39628>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '3770',
 'viewCount': []}
2020-03-23 17:41:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:41:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37435>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '2304',
 'viewCount': []}
2020-03-23 17:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:41:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37366>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '73',
 'viewCount': []}
2020-03-23 17:41:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:41:46 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39705>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '本站排名:109',
 'viewCount': []}
2020-03-23 17:41:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:41:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11088>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '26',
 'viewCount': []}
2020-03-23 17:41:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:41:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11057>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '7',
 'viewCount': []}
2020-03-23 17:41:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:41:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39654>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '2245',
 'viewCount': []}
2020-03-23 17:41:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:41:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39526>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '4133',
 'viewCount': []}
2020-03-23 17:41:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:41:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39693>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '本站排名:7470',
 'viewCount': []}
2020-03-23 17:41:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:41:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39662>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '本站排名:9794',
 'viewCount': []}
2020-03-23 17:41:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:41:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/33701>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '9',
 'viewCount': []}
2020-03-23 17:41:54 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:41:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5646,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 145902,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 13.981155,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 41, 54, 597284),
 'item_scraped_count': 12,
 'log_count/DEBUG': 25,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2020, 3, 23, 9, 41, 40, 616129)}
2020-03-23 17:41:54 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-23 17:42:20 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-23 17:42:20 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-23 17:42:20 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-23 17:42:20 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like '
               'Gecko) Chrome/19.0.1061.0 Safari/536.3'}
2020-03-23 17:42:20 [scrapy.extensions.telnet] INFO: Telnet Password: 92147257742c093b
2020-03-23 17:42:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-23 17:42:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-23 17:42:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-23 17:42:20 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-23 17:42:20 [scrapy.core.engine] INFO: Spider opened
2020-03-23 17:42:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-23 17:42:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-23 17:42:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-23 17:42:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39628> (referer: http://www.rrys2019.com)
2020-03-23 17:42:21 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39628>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '3770',
 'viewCount': []}
2020-03-23 17:42:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37435> (referer: http://www.rrys2019.com)
2020-03-23 17:42:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37435>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '2304',
 'viewCount': []}
2020-03-23 17:42:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-23 17:42:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37366>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '73',
 'viewCount': []}
2020-03-23 17:42:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39705> (referer: http://www.rrys2019.com)
2020-03-23 17:42:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39705>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '109',
 'viewCount': []}
2020-03-23 17:42:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11088> (referer: http://www.rrys2019.com)
2020-03-23 17:42:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11088>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '26',
 'viewCount': []}
2020-03-23 17:42:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/11057> (referer: http://www.rrys2019.com)
2020-03-23 17:42:26 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/11057>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '7',
 'viewCount': []}
2020-03-23 17:42:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-23 17:42:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39654>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '2245',
 'viewCount': []}
2020-03-23 17:42:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-23 17:42:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39526>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '4133',
 'viewCount': []}
2020-03-23 17:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-23 17:42:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39693>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7470',
 'viewCount': []}
2020-03-23 17:42:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-23 17:42:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39662>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9794',
 'viewCount': []}
2020-03-23 17:42:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-23 17:42:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/33701>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '9',
 'viewCount': []}
2020-03-23 17:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/10945> (referer: http://www.rrys2019.com)
2020-03-23 17:42:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/10945>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '58',
 'viewCount': []}
2020-03-23 17:42:33 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-23 17:42:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4216,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 145902,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 13.146921,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 23, 9, 42, 33, 526552),
 'item_scraped_count': 12,
 'log_count/DEBUG': 25,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'start_time': datetime.datetime(2020, 3, 23, 9, 42, 20, 379631)}
2020-03-23 17:42:33 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 15:13:17 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 15:13:17 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 15:13:17 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 15:13:17 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, '
               'like Gecko) Chrome/19.0.1055.1 Safari/535.24'}
2020-03-25 15:13:17 [scrapy.extensions.telnet] INFO: Telnet Password: 2057f837ccf2590c
2020-03-25 15:13:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 15:13:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 15:13:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 15:13:17 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 15:13:17 [scrapy.core.engine] INFO: Spider opened
2020-03-25 15:13:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 15:13:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 15:13:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.rrys2019.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: www.rrys2019.com.
2020-03-25 15:13:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.rrys2019.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: www.rrys2019.com.
2020-03-25 15:14:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 15:14:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 15:14:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/33701>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '9',
 'viewCount': ['浏览次数：']}
2020-03-25 15:14:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 15:14:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39662>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9709',
 'viewCount': ['浏览次数：']}
2020-03-25 15:14:17 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 2 items (at 2 items/min)
2020-03-25 15:14:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 15:14:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/37366>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '72',
 'viewCount': ['浏览次数：']}
2020-03-25 15:14:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 15:14:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/35493>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '42',
 'viewCount': ['浏览次数：']}
2020-03-25 15:14:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 15:14:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39127>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '106',
 'viewCount': ['浏览次数：']}
2020-03-25 15:14:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 15:14:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/38944>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4384',
 'viewCount': ['浏览次数：']}
2020-03-25 15:14:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 15:14:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39714>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4813',
 'viewCount': ['浏览次数：']}
2020-03-25 15:14:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 15:14:21 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39526>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '4113',
 'viewCount': ['浏览次数：']}
2020-03-25 15:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 15:14:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/33190>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '39',
 'viewCount': ['浏览次数：']}
2020-03-25 15:14:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 15:14:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39693>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7571',
 'viewCount': ['浏览次数：']}
2020-03-25 15:14:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 15:14:26 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39654>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '1660',
 'viewCount': ['浏览次数：']}
2020-03-25 15:14:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 15:14:26 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/39716>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '999999',
 'viewCount': ['浏览次数：']}
2020-03-25 15:14:26 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 15:14:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 2,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 2,
 'downloader/request_bytes': 4851,
 'downloader/request_count': 15,
 'downloader/request_method_count/GET': 15,
 'downloader/response_bytes': 146501,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 68.901079,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 7, 14, 26, 746214),
 'item_scraped_count': 12,
 'log_count/DEBUG': 27,
 'log_count/INFO': 11,
 'request_depth_max': 1,
 'response_received_count': 13,
 'retry/count': 2,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 2,
 'scheduler/dequeued': 15,
 'scheduler/dequeued/memory': 15,
 'scheduler/enqueued': 15,
 'scheduler/enqueued/memory': 15,
 'start_time': datetime.datetime(2020, 3, 25, 7, 13, 17, 845135)}
2020-03-25 15:14:26 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 21:37:42 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 21:37:42 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 21:37:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 21:37:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, '
               'like Gecko) Chrome/19.0.1061.1 Safari/536.3'}
2020-03-25 21:37:42 [scrapy.extensions.telnet] INFO: Telnet Password: aea3d9328363be43
2020-03-25 21:37:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 21:37:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 21:37:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 21:37:43 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 21:37:43 [scrapy.core.engine] INFO: Spider opened
2020-03-25 21:37:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 21:37:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 21:37:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 21:37:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com> (referer: None)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 24, in parse
    item['resourceId'] = link.split('/')[-1]
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 89, in __setitem__
    raise KeyError("%s does not support field: %s" %
KeyError: 'RrysItem does not support field: resourceId'
2020-03-25 21:37:44 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 21:37:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 287,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 23539,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.465615,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 13, 37, 44, 571288),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2020, 3, 25, 13, 37, 43, 105673)}
2020-03-25 21:37:44 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 21:38:23 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 21:38:23 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 21:38:23 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 21:38:23 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, '
               'like Gecko) Chrome/19.0.1055.1 Safari/535.24'}
2020-03-25 21:38:23 [scrapy.extensions.telnet] INFO: Telnet Password: 01c3121f1e73db92
2020-03-25 21:38:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 21:38:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 21:38:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 21:38:24 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 21:38:24 [scrapy.core.engine] INFO: Spider opened
2020-03-25 21:38:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 21:38:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 21:38:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 21:38:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com> (referer: None)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 25, in parse
    item['resourceId'] = link.split('/')[-1]
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 89, in __setitem__
    raise KeyError("%s does not support field: %s" %
KeyError: 'RrysItem does not support field: resourceId'
2020-03-25 21:38:24 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 21:38:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 285,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 23539,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.282475,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 13, 38, 24, 355503),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2020, 3, 25, 13, 38, 24, 73028)}
2020-03-25 21:38:24 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 21:39:24 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 21:39:24 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 21:39:24 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 21:39:24 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)'}
2020-03-25 21:39:24 [scrapy.extensions.telnet] INFO: Telnet Password: 36a3b7e12992f92f
2020-03-25 21:39:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 21:39:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 21:39:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 21:39:24 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 21:39:24 [scrapy.core.engine] INFO: Spider opened
2020-03-25 21:39:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 21:39:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 21:39:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 21:39:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com> (referer: None)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 25, in parse
    item['resourceId'] = link.split('/')[-1]
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 89, in __setitem__
    raise KeyError("%s does not support field: %s" %
KeyError: 'RrysItem does not support field: resourceId'
2020-03-25 21:39:24 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 21:39:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 23539,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.282243,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 13, 39, 24, 930915),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2020, 3, 25, 13, 39, 24, 648672)}
2020-03-25 21:39:24 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 21:39:45 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 21:39:45 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 21:39:45 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 21:39:45 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)'}
2020-03-25 21:39:45 [scrapy.extensions.telnet] INFO: Telnet Password: fe422ed1be5bafaf
2020-03-25 21:39:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 21:39:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 21:39:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 21:39:45 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 21:39:45 [scrapy.core.engine] INFO: Spider opened
2020-03-25 21:39:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 21:39:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 21:39:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 21:39:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com> (referer: None)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 25, in parse
    item['resourceId'] = link.split('/')[-1]
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 89, in __setitem__
    raise KeyError("%s does not support field: %s" %
KeyError: 'RrysItem does not support field: resourceId'
2020-03-25 21:39:45 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 21:39:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 23539,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.2816,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 13, 39, 45, 718524),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2020, 3, 25, 13, 39, 45, 436924)}
2020-03-25 21:39:45 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 21:40:10 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 21:40:10 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 21:40:10 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 21:40:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like '
               'Gecko) Chrome/19.0.1061.1 Safari/536.3'}
2020-03-25 21:40:10 [scrapy.extensions.telnet] INFO: Telnet Password: de65f4380fa52a19
2020-03-25 21:40:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 21:40:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 21:40:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 21:40:10 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 21:40:10 [scrapy.core.engine] INFO: Spider opened
2020-03-25 21:40:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 21:40:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 21:40:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 21:40:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com> (referer: None)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 25, in parse
    item['resourceId'] = link.split('/')[-1]
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 89, in __setitem__
    raise KeyError("%s does not support field: %s" %
KeyError: 'RrysItem does not support field: resourceId'
2020-03-25 21:40:10 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 21:40:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 280,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 23539,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.354091,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 13, 40, 11, 980),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2020, 3, 25, 13, 40, 10, 646889)}
2020-03-25 21:40:11 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 21:40:33 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 21:40:33 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 21:40:33 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 21:40:33 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)'}
2020-03-25 21:40:33 [scrapy.extensions.telnet] INFO: Telnet Password: 5e9ab0f5ab9a2af9
2020-03-25 21:40:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 21:40:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 21:40:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 21:40:33 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 21:40:33 [scrapy.core.engine] INFO: Spider opened
2020-03-25 21:40:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 21:40:33 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 21:40:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 21:40:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com> (referer: None)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 25, in parse
    item['resourceId'] = link.split('/')[-1]
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 89, in __setitem__
    raise KeyError("%s does not support field: %s" %
KeyError: 'RrysItem does not support field: resourceId'
2020-03-25 21:40:33 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 21:40:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 239,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 23539,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.460852,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 13, 40, 33, 818227),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2020, 3, 25, 13, 40, 33, 357375)}
2020-03-25 21:40:33 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 21:41:44 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 21:41:44 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 21:41:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 21:41:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, '
               'like Gecko) Chrome/19.0.1061.1 Safari/536.3'}
2020-03-25 21:41:44 [scrapy.extensions.telnet] INFO: Telnet Password: bd765c37ba99f89a
2020-03-25 21:41:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 21:41:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 21:41:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 21:41:44 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 21:41:44 [scrapy.core.engine] INFO: Spider opened
2020-03-25 21:41:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 21:41:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 21:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 21:41:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 21:41:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 21:41:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 21:41:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 21:41:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 21:41:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 21:41:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 21:41:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 21:41:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 21:41:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 21:41:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 21:42:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 21:42:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv> (referer: http://www.rrys2019.com/resource/37366)
2020-03-25 21:42:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv> (referer: http://www.rrys2019.com/resource/37366)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:42:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv> (referer: http://www.rrys2019.com/resource/39127)
2020-03-25 21:42:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv> (referer: http://www.rrys2019.com/resource/39127)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:42:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv> (referer: http://www.rrys2019.com/resource/33190)
2020-03-25 21:42:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv> (referer: http://www.rrys2019.com/resource/33190)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:42:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv> (referer: http://www.rrys2019.com/resource/39526)
2020-03-25 21:42:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv> (referer: http://www.rrys2019.com/resource/39526)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:42:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv> (referer: http://www.rrys2019.com/resource/39693)
2020-03-25 21:42:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv> (referer: http://www.rrys2019.com/resource/39693)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:42:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv> (referer: http://www.rrys2019.com/resource/39654)
2020-03-25 21:42:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv> (referer: http://www.rrys2019.com/resource/39654)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:42:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv> (referer: http://www.rrys2019.com/resource/38944)
2020-03-25 21:42:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv> (referer: http://www.rrys2019.com/resource/38944)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:42:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv> (referer: http://www.rrys2019.com/resource/39716)
2020-03-25 21:42:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv> (referer: http://www.rrys2019.com/resource/39716)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:42:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv> (referer: http://www.rrys2019.com/resource/33701)
2020-03-25 21:42:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv> (referer: http://www.rrys2019.com/resource/33701)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:42:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv> (referer: http://www.rrys2019.com/resource/39662)
2020-03-25 21:42:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv> (referer: http://www.rrys2019.com/resource/39662)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:42:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv> (referer: http://www.rrys2019.com/resource/35493)
2020-03-25 21:42:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv> (referer: http://www.rrys2019.com/resource/35493)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:42:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv> (referer: http://www.rrys2019.com/resource/39714)
2020-03-25 21:42:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv> (referer: http://www.rrys2019.com/resource/39714)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:42:15 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 21:42:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8819,
 'downloader/request_count': 25,
 'downloader/request_method_count/GET': 25,
 'downloader/response_bytes': 171619,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'elapsed_time_seconds': 31.212063,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 13, 42, 15, 767087),
 'log_count/DEBUG': 25,
 'log_count/ERROR': 12,
 'log_count/INFO': 10,
 'request_depth_max': 2,
 'response_received_count': 25,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'spider_exceptions/JSONDecodeError': 12,
 'start_time': datetime.datetime(2020, 3, 25, 13, 41, 44, 555024)}
2020-03-25 21:42:15 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 21:43:21 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 21:43:21 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 21:43:21 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 21:43:21 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like '
               'Gecko) Chrome/19.0.1061.0 Safari/536.3'}
2020-03-25 21:43:21 [scrapy.extensions.telnet] INFO: Telnet Password: b9f595ff89031fd9
2020-03-25 21:43:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 21:43:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 21:43:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 21:43:22 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 21:43:22 [scrapy.core.engine] INFO: Spider opened
2020-03-25 21:43:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 21:43:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 21:43:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 21:43:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 21:43:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 21:43:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 21:43:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 21:43:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 21:43:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 21:43:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 21:43:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 21:43:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 21:43:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 21:43:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 21:43:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 21:43:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv> (referer: http://www.rrys2019.com/resource/33701)
2020-03-25 21:43:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv> (referer: http://www.rrys2019.com/resource/33701)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:43:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv> (referer: http://www.rrys2019.com/resource/39662)
2020-03-25 21:43:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv> (referer: http://www.rrys2019.com/resource/39662)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:43:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv> (referer: http://www.rrys2019.com/resource/35493)
2020-03-25 21:43:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv> (referer: http://www.rrys2019.com/resource/35493)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:43:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv> (referer: http://www.rrys2019.com/resource/39714)
2020-03-25 21:43:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv> (referer: http://www.rrys2019.com/resource/39714)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:43:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv> (referer: http://www.rrys2019.com/resource/37366)
2020-03-25 21:43:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv> (referer: http://www.rrys2019.com/resource/37366)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:43:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv> (referer: http://www.rrys2019.com/resource/39127)
2020-03-25 21:43:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv> (referer: http://www.rrys2019.com/resource/39127)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:43:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv> (referer: http://www.rrys2019.com/resource/33190)
2020-03-25 21:43:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv> (referer: http://www.rrys2019.com/resource/33190)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:43:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv> (referer: http://www.rrys2019.com/resource/39526)
2020-03-25 21:43:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv> (referer: http://www.rrys2019.com/resource/39526)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:43:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv> (referer: http://www.rrys2019.com/resource/39693)
2020-03-25 21:43:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv> (referer: http://www.rrys2019.com/resource/39693)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:43:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv> (referer: http://www.rrys2019.com/resource/38944)
2020-03-25 21:43:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv> (referer: http://www.rrys2019.com/resource/38944)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:43:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv> (referer: http://www.rrys2019.com/resource/39654)
2020-03-25 21:43:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv> (referer: http://www.rrys2019.com/resource/39654)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:43:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv> (referer: http://www.rrys2019.com/resource/39716)
2020-03-25 21:43:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv> (referer: http://www.rrys2019.com/resource/39716)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 52, in parse3
    data = json.loads(json_str)
  File "c:\programs\python\python38\lib\json\__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "c:\programs\python\python38\lib\json\decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 1 column 13 (char 12)
2020-03-25 21:43:54 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 21:43:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8644,
 'downloader/request_count': 25,
 'downloader/request_method_count/GET': 25,
 'downloader/response_bytes': 171566,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'elapsed_time_seconds': 32.349493,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 13, 43, 54, 453259),
 'log_count/DEBUG': 25,
 'log_count/ERROR': 12,
 'log_count/INFO': 10,
 'request_depth_max': 2,
 'response_received_count': 25,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'spider_exceptions/JSONDecodeError': 12,
 'start_time': datetime.datetime(2020, 3, 25, 13, 43, 22, 103766)}
2020-03-25 21:43:54 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 21:44:49 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 21:44:49 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 21:44:49 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 21:44:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/66.0.3359.139 '
               'Safari/537.36Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 '
               '(KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3'}
2020-03-25 21:44:49 [scrapy.extensions.telnet] INFO: Telnet Password: b9d33e56e6688e9c
2020-03-25 21:44:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 21:44:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 21:44:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 21:44:49 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 21:44:49 [scrapy.core.engine] INFO: Spider opened
2020-03-25 21:44:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 21:44:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 21:44:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 21:44:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 21:44:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 21:44:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 21:44:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 21:44:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 21:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 21:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 21:44:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 21:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 21:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 21:45:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 21:45:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 21:45:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv> (referer: http://www.rrys2019.com/resource/38944)
2020-03-25 21:45:06 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4384'}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 17, in process_item
    viewCount = item['viewCount']
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 83, in __getitem__
    return self._values[key]
KeyError: 'viewCount'
2020-03-25 21:45:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv> (referer: http://www.rrys2019.com/resource/39716)
2020-03-25 21:45:07 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '999999'}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 17, in process_item
    viewCount = item['viewCount']
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 83, in __getitem__
    return self._values[key]
KeyError: 'viewCount'
2020-03-25 21:45:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv> (referer: http://www.rrys2019.com/resource/33701)
2020-03-25 21:45:09 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png', 'score': '9'}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 17, in process_item
    viewCount = item['viewCount']
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 83, in __getitem__
    return self._values[key]
KeyError: 'viewCount'
2020-03-25 21:45:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv> (referer: http://www.rrys2019.com/resource/39127)
2020-03-25 21:45:09 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '106'}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 17, in process_item
    viewCount = item['viewCount']
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 83, in __getitem__
    return self._values[key]
KeyError: 'viewCount'
2020-03-25 21:45:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv> (referer: http://www.rrys2019.com/resource/33190)
2020-03-25 21:45:11 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png', 'score': '38'}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 17, in process_item
    viewCount = item['viewCount']
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 83, in __getitem__
    return self._values[key]
KeyError: 'viewCount'
2020-03-25 21:45:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv> (referer: http://www.rrys2019.com/resource/39526)
2020-03-25 21:45:12 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '4113'}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 17, in process_item
    viewCount = item['viewCount']
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 83, in __getitem__
    return self._values[key]
KeyError: 'viewCount'
2020-03-25 21:45:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv> (referer: http://www.rrys2019.com/resource/39693)
2020-03-25 21:45:13 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7571'}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 17, in process_item
    viewCount = item['viewCount']
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 83, in __getitem__
    return self._values[key]
KeyError: 'viewCount'
2020-03-25 21:45:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv> (referer: http://www.rrys2019.com/resource/39654)
2020-03-25 21:45:14 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '1660'}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 17, in process_item
    viewCount = item['viewCount']
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 83, in __getitem__
    return self._values[key]
KeyError: 'viewCount'
2020-03-25 21:45:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv> (referer: http://www.rrys2019.com/resource/39662)
2020-03-25 21:45:16 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9709'}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 17, in process_item
    viewCount = item['viewCount']
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 83, in __getitem__
    return self._values[key]
KeyError: 'viewCount'
2020-03-25 21:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv> (referer: http://www.rrys2019.com/resource/35493)
2020-03-25 21:45:17 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png', 'score': '42'}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 17, in process_item
    viewCount = item['viewCount']
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 83, in __getitem__
    return self._values[key]
KeyError: 'viewCount'
2020-03-25 21:45:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv> (referer: http://www.rrys2019.com/resource/39714)
2020-03-25 21:45:18 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4813'}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 17, in process_item
    viewCount = item['viewCount']
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 83, in __getitem__
    return self._values[key]
KeyError: 'viewCount'
2020-03-25 21:45:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv> (referer: http://www.rrys2019.com/resource/37366)
2020-03-25 21:45:19 [scrapy.core.scraper] ERROR: Error processing {'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png', 'score': '72'}
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\pipelines.py", line 17, in process_item
    viewCount = item['viewCount']
  File "c:\programs\python\python38\lib\site-packages\scrapy\item.py", line 83, in __getitem__
    return self._values[key]
KeyError: 'viewCount'
2020-03-25 21:45:19 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 21:45:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 11394,
 'downloader/request_count': 25,
 'downloader/request_method_count/GET': 25,
 'downloader/response_bytes': 172175,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'elapsed_time_seconds': 29.59844,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 13, 45, 19, 374493),
 'log_count/DEBUG': 25,
 'log_count/ERROR': 12,
 'log_count/INFO': 10,
 'request_depth_max': 2,
 'response_received_count': 25,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2020, 3, 25, 13, 44, 49, 776053)}
2020-03-25 21:45:19 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 21:49:13 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 21:49:13 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 21:49:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 21:49:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, '
               'like Gecko) Chrome/19.0.1062.0 Safari/536.3'}
2020-03-25 21:49:13 [scrapy.extensions.telnet] INFO: Telnet Password: eb2c521bf272d9e3
2020-03-25 21:49:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 21:49:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 21:49:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 21:49:14 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 21:49:14 [scrapy.core.engine] INFO: Spider opened
2020-03-25 21:49:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 21:49:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 21:49:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 21:49:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 21:49:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 21:49:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 21:49:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 21:49:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 21:49:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 21:49:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 21:49:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 21:49:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 21:49:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 21:49:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 21:49:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 21:49:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv> (referer: http://www.rrys2019.com/resource/35493)
2020-03-25 21:49:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '42',
 'viewCount': '1359681'}
2020-03-25 21:49:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv> (referer: http://www.rrys2019.com/resource/37366)
2020-03-25 21:49:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '72',
 'viewCount': '753363'}
2020-03-25 21:49:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv> (referer: http://www.rrys2019.com/resource/39714)
2020-03-25 21:49:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4813',
 'viewCount': '10281'}
2020-03-25 21:49:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv> (referer: http://www.rrys2019.com/resource/39127)
2020-03-25 21:49:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '106',
 'viewCount': '7492'}
2020-03-25 21:49:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv> (referer: http://www.rrys2019.com/resource/33190)
2020-03-25 21:49:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '38',
 'viewCount': '2433301'}
2020-03-25 21:49:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv> (referer: http://www.rrys2019.com/resource/39526)
2020-03-25 21:49:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '4113',
 'viewCount': '115087'}
2020-03-25 21:49:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv> (referer: http://www.rrys2019.com/resource/39693)
2020-03-25 21:49:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7571',
 'viewCount': '42453'}
2020-03-25 21:49:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv> (referer: http://www.rrys2019.com/resource/39654)
2020-03-25 21:49:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '1660',
 'viewCount': '53303'}
2020-03-25 21:49:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv> (referer: http://www.rrys2019.com/resource/38944)
2020-03-25 21:49:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4384',
 'viewCount': '18341'}
2020-03-25 21:49:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv> (referer: http://www.rrys2019.com/resource/39716)
2020-03-25 21:49:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '999999',
 'viewCount': '25121'}
2020-03-25 21:49:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv> (referer: http://www.rrys2019.com/resource/33701)
2020-03-25 21:49:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '9',
 'viewCount': '7030395'}
2020-03-25 21:49:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv> (referer: http://www.rrys2019.com/resource/39662)
2020-03-25 21:49:43 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9709',
 'viewCount': '57094'}
2020-03-25 21:49:43 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 21:49:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8819,
 'downloader/request_count': 25,
 'downloader/request_method_count/GET': 25,
 'downloader/response_bytes': 172139,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'elapsed_time_seconds': 29.467875,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 13, 49, 43, 528471),
 'item_scraped_count': 12,
 'log_count/DEBUG': 37,
 'log_count/INFO': 10,
 'request_depth_max': 2,
 'response_received_count': 25,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2020, 3, 25, 13, 49, 14, 60596)}
2020-03-25 21:49:43 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 21:53:11 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 21:53:11 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 21:53:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 21:53:11 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, '
               'like Gecko) Chrome/19.0.1061.1 Safari/536.3'}
2020-03-25 21:53:11 [scrapy.extensions.telnet] INFO: Telnet Password: ec3d95e5ccb7f6ec
2020-03-25 21:53:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 21:53:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 21:53:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 21:53:11 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 21:53:11 [scrapy.core.engine] INFO: Spider opened
2020-03-25 21:53:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 21:53:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 21:53:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 21:53:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 21:53:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 21:53:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 21:53:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 21:53:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 21:53:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 21:53:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 21:53:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 21:53:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 21:53:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 21:53:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 21:53:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 21:53:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv> (referer: http://www.rrys2019.com/resource/39654)
2020-03-25 21:53:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '1660',
 'viewCount': '53373'}
2020-03-25 21:53:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv> (referer: http://www.rrys2019.com/resource/38944)
2020-03-25 21:53:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4384',
 'viewCount': '18464'}
2020-03-25 21:53:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv> (referer: http://www.rrys2019.com/resource/39716)
2020-03-25 21:53:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '999999',
 'viewCount': '25222'}
2020-03-25 21:53:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv> (referer: http://www.rrys2019.com/resource/33701)
2020-03-25 21:53:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '9',
 'viewCount': '7030557'}
2020-03-25 21:53:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv> (referer: http://www.rrys2019.com/resource/35493)
2020-03-25 21:53:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '42',
 'viewCount': '1359697'}
2020-03-25 21:53:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv> (referer: http://www.rrys2019.com/resource/39662)
2020-03-25 21:53:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9709',
 'viewCount': '57120'}
2020-03-25 21:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv> (referer: http://www.rrys2019.com/resource/39714)
2020-03-25 21:53:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4813',
 'viewCount': '10296'}
2020-03-25 21:53:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv> (referer: http://www.rrys2019.com/resource/37366)
2020-03-25 21:53:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '72',
 'viewCount': '753398'}
2020-03-25 21:53:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv> (referer: http://www.rrys2019.com/resource/39127)
2020-03-25 21:53:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '106',
 'viewCount': '7525'}
2020-03-25 21:53:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv> (referer: http://www.rrys2019.com/resource/33190)
2020-03-25 21:53:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '38',
 'viewCount': '2433329'}
2020-03-25 21:53:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv> (referer: http://www.rrys2019.com/resource/39526)
2020-03-25 21:53:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '4113',
 'viewCount': '115115'}
2020-03-25 21:53:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv> (referer: http://www.rrys2019.com/resource/39693)
2020-03-25 21:53:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7571',
 'viewCount': '42518'}
2020-03-25 21:53:42 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 21:53:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8819,
 'downloader/request_count': 25,
 'downloader/request_method_count/GET': 25,
 'downloader/response_bytes': 172153,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'elapsed_time_seconds': 30.490671,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 13, 53, 42, 359440),
 'item_scraped_count': 12,
 'log_count/DEBUG': 37,
 'log_count/INFO': 10,
 'request_depth_max': 2,
 'response_received_count': 25,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2020, 3, 25, 13, 53, 11, 868769)}
2020-03-25 21:53:42 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 22:05:37 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 22:05:37 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 22:05:37 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 22:05:37 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, '
               'like Gecko) Chrome/19.0.1062.0 Safari/536.3'}
2020-03-25 22:05:37 [scrapy.extensions.telnet] INFO: Telnet Password: 62481bb2693cbd84
2020-03-25 22:05:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 22:05:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 22:05:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 22:05:37 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 22:05:37 [scrapy.core.engine] INFO: Spider opened
2020-03-25 22:05:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 22:05:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 22:05:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 22:05:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 22:05:39 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(2)
IndexError: no such group
2020-03-25 22:05:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 22:05:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(2)
IndexError: no such group
2020-03-25 22:05:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 22:05:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(2)
IndexError: no such group
2020-03-25 22:05:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 22:05:42 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(2)
IndexError: no such group
2020-03-25 22:05:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 22:05:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(2)
IndexError: no such group
2020-03-25 22:05:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 22:05:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(2)
IndexError: no such group
2020-03-25 22:05:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 22:05:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(2)
IndexError: no such group
2020-03-25 22:05:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 22:05:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(2)
IndexError: no such group
2020-03-25 22:05:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 22:05:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(2)
IndexError: no such group
2020-03-25 22:05:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 22:05:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(2)
IndexError: no such group
2020-03-25 22:05:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 22:05:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(2)
IndexError: no such group
2020-03-25 22:05:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 22:05:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(2)
IndexError: no such group
2020-03-25 22:05:52 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 22:05:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4307,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 147010,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 15.034525,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 14, 5, 52, 445397),
 'log_count/DEBUG': 13,
 'log_count/ERROR': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'spider_exceptions/IndexError': 12,
 'start_time': datetime.datetime(2020, 3, 25, 14, 5, 37, 410872)}
2020-03-25 22:05:52 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 22:05:57 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 22:05:57 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 22:05:57 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 22:05:57 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/66.0.3359.139 '
               'Safari/537.36Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 '
               '(KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3'}
2020-03-25 22:05:57 [scrapy.extensions.telnet] INFO: Telnet Password: 8f1c82b57b4b2508
2020-03-25 22:05:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 22:05:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 22:05:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 22:05:57 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 22:05:57 [scrapy.core.engine] INFO: Spider opened
2020-03-25 22:05:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 22:05:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 22:05:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 22:05:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 22:05:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:06:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 22:06:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:06:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 22:06:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:06:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 22:06:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:06:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 22:06:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:06:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 22:06:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:06:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 22:06:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:06:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 22:06:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:06:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 22:06:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:06:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 22:06:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:06:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 22:06:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:06:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 22:06:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search('\w+$', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:06:13 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 22:06:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 5646,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 147010,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 15.442461,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 14, 6, 13, 182077),
 'log_count/DEBUG': 13,
 'log_count/ERROR': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'spider_exceptions/IndexError': 12,
 'start_time': datetime.datetime(2020, 3, 25, 14, 5, 57, 739616)}
2020-03-25 22:06:13 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 22:06:55 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 22:06:55 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 22:06:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 22:06:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like '
               'Gecko) Chrome/19.0.1061.0 Safari/536.3'}
2020-03-25 22:06:55 [scrapy.extensions.telnet] INFO: Telnet Password: 833f4d70107f6dd9
2020-03-25 22:06:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 22:06:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 22:06:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 22:06:56 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 22:06:56 [scrapy.core.engine] INFO: Spider opened
2020-03-25 22:06:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 22:06:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 22:06:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 22:06:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 22:06:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 22:06:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 22:07:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 22:07:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 22:07:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 22:07:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 22:07:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 22:07:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 22:07:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 22:07:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 22:07:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 22:07:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv> (referer: http://www.rrys2019.com/resource/39716)
2020-03-25 22:07:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '999999',
 'viewCount': '25559'}
2020-03-25 22:07:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv> (referer: http://www.rrys2019.com/resource/33701)
2020-03-25 22:07:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '9',
 'viewCount': '7030981'}
2020-03-25 22:07:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv> (referer: http://www.rrys2019.com/resource/35493)
2020-03-25 22:07:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '42',
 'viewCount': '1359762'}
2020-03-25 22:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv> (referer: http://www.rrys2019.com/resource/39662)
2020-03-25 22:07:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9709',
 'viewCount': '57194'}
2020-03-25 22:07:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv> (referer: http://www.rrys2019.com/resource/39714)
2020-03-25 22:07:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4813',
 'viewCount': '10361'}
2020-03-25 22:07:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv> (referer: http://www.rrys2019.com/resource/37366)
2020-03-25 22:07:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '72',
 'viewCount': '753506'}
2020-03-25 22:07:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv> (referer: http://www.rrys2019.com/resource/39127)
2020-03-25 22:07:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '106',
 'viewCount': '7641'}
2020-03-25 22:07:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv> (referer: http://www.rrys2019.com/resource/33190)
2020-03-25 22:07:21 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '38',
 'viewCount': '2433418'}
2020-03-25 22:07:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv> (referer: http://www.rrys2019.com/resource/39526)
2020-03-25 22:07:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '4113',
 'viewCount': '115260'}
2020-03-25 22:07:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv> (referer: http://www.rrys2019.com/resource/39693)
2020-03-25 22:07:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7571',
 'viewCount': '42717'}
2020-03-25 22:07:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv> (referer: http://www.rrys2019.com/resource/39654)
2020-03-25 22:07:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '1660',
 'viewCount': '53579'}
2020-03-25 22:07:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv> (referer: http://www.rrys2019.com/resource/38944)
2020-03-25 22:07:26 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4384',
 'viewCount': '18981'}
2020-03-25 22:07:26 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 22:07:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8644,
 'downloader/request_count': 25,
 'downloader/request_method_count/GET': 25,
 'downloader/response_bytes': 172123,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'elapsed_time_seconds': 30.193346,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 14, 7, 26, 222510),
 'item_scraped_count': 12,
 'log_count/DEBUG': 37,
 'log_count/INFO': 10,
 'request_depth_max': 2,
 'response_received_count': 25,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2020, 3, 25, 14, 6, 56, 29164)}
2020-03-25 22:07:26 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 22:10:41 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 22:10:41 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 22:10:41 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 22:10:41 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like '
               'Gecko) Chrome/19.0.1061.1 Safari/536.3'}
2020-03-25 22:10:41 [scrapy.extensions.telnet] INFO: Telnet Password: 3652c561e8f15252
2020-03-25 22:10:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 22:10:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 22:10:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 22:10:41 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 22:10:41 [scrapy.core.engine] INFO: Spider opened
2020-03-25 22:10:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 22:10:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 22:10:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 22:10:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 22:10:43 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search(r'/\w+?-big', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:10:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 22:10:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search(r'/\w+?-big', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:10:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 22:10:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search(r'/\w+?-big', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:10:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 22:10:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search(r'/\w+?-big', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:10:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 22:10:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search(r'/\w+?-big', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:10:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 22:10:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search(r'/\w+?-big', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:10:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 22:10:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search(r'/\w+?-big', imgSrc).group(1)
IndexError: no such group
2020-03-25 22:10:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 22:10:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search(r'/\w+?-big', imgSrc)
IndexError: no such group
2020-03-25 22:10:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 22:10:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search(r'/\w+?-big', imgSrc)
IndexError: no such group
2020-03-25 22:10:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 22:10:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search(r'/\w+?-big', imgSrc)
IndexError: no such group
2020-03-25 22:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 22:10:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search(r'/\w+?-big', imgSrc)
IndexError: no such group
2020-03-25 22:10:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 22:10:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 41, in parse2
    s = re.search(r'/\w+?-big', imgSrc)
IndexError: no such group
2020-03-25 22:10:58 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 22:10:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4216,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 147008,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 16.331565,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 14, 10, 58, 261358),
 'log_count/DEBUG': 13,
 'log_count/ERROR': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'spider_exceptions/IndexError': 12,
 'start_time': datetime.datetime(2020, 3, 25, 14, 10, 41, 929793)}
2020-03-25 22:10:58 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 22:11:01 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 22:11:01 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 22:11:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 22:11:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like '
               'Gecko) Chrome/19.0.1061.0 Safari/536.3'}
2020-03-25 22:11:01 [scrapy.extensions.telnet] INFO: Telnet Password: fff6e5dd503cce61
2020-03-25 22:11:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 22:11:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 22:11:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 22:11:02 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 22:11:02 [scrapy.core.engine] INFO: Spider opened
2020-03-25 22:11:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 22:11:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 22:11:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 22:11:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 22:11:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 22:11:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 22:11:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 22:11:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 22:11:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 22:11:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 22:11:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 22:11:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 22:11:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 22:11:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 22:11:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 22:11:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv> (referer: http://www.rrys2019.com/resource/33190)
2020-03-25 22:11:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '38',
 'viewCount': '2433451'}
2020-03-25 22:11:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv> (referer: http://www.rrys2019.com/resource/39127)
2020-03-25 22:11:19 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '106',
 'viewCount': '7663'}
2020-03-25 22:11:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv> (referer: http://www.rrys2019.com/resource/39526)
2020-03-25 22:11:21 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '4113',
 'viewCount': '115297'}
2020-03-25 22:11:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv> (referer: http://www.rrys2019.com/resource/39693)
2020-03-25 22:11:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7571',
 'viewCount': '42786'}
2020-03-25 22:11:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv> (referer: http://www.rrys2019.com/resource/39654)
2020-03-25 22:11:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '1660',
 'viewCount': '53633'}
2020-03-25 22:11:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv> (referer: http://www.rrys2019.com/resource/38944)
2020-03-25 22:11:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4384',
 'viewCount': '19128'}
2020-03-25 22:11:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv> (referer: http://www.rrys2019.com/resource/39716)
2020-03-25 22:11:26 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '999999',
 'viewCount': '25679'}
2020-03-25 22:11:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv> (referer: http://www.rrys2019.com/resource/33701)
2020-03-25 22:11:27 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '9',
 'viewCount': '7031110'}
2020-03-25 22:11:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv> (referer: http://www.rrys2019.com/resource/35493)
2020-03-25 22:11:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '42',
 'viewCount': '1359781'}
2020-03-25 22:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv> (referer: http://www.rrys2019.com/resource/39662)
2020-03-25 22:11:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9709',
 'viewCount': '57215'}
2020-03-25 22:11:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv> (referer: http://www.rrys2019.com/resource/39714)
2020-03-25 22:11:31 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4813',
 'viewCount': '10392'}
2020-03-25 22:11:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv> (referer: http://www.rrys2019.com/resource/37366)
2020-03-25 22:11:32 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '72',
 'viewCount': '753537'}
2020-03-25 22:11:32 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 22:11:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8644,
 'downloader/request_count': 25,
 'downloader/request_method_count/GET': 25,
 'downloader/response_bytes': 172089,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'elapsed_time_seconds': 30.395574,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 14, 11, 32, 473901),
 'item_scraped_count': 12,
 'log_count/DEBUG': 37,
 'log_count/INFO': 10,
 'request_depth_max': 2,
 'response_received_count': 25,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2020, 3, 25, 14, 11, 2, 78327)}
2020-03-25 22:11:32 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 22:11:37 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 22:11:37 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 22:11:37 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 22:11:37 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like '
               'Gecko) Chrome/19.0.1061.1 Safari/536.3'}
2020-03-25 22:11:37 [scrapy.extensions.telnet] INFO: Telnet Password: 536074c0e35299e1
2020-03-25 22:11:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 22:11:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 22:11:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 22:11:37 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 22:11:37 [scrapy.core.engine] INFO: Spider opened
2020-03-25 22:11:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 22:11:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 22:11:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 22:11:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 22:11:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 22:11:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 22:11:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 22:11:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 22:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 22:11:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 22:11:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 22:11:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 22:11:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 22:11:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 22:11:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 22:11:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv> (referer: http://www.rrys2019.com/resource/39662)
2020-03-25 22:11:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9709',
 'viewCount': '57223'}
2020-03-25 22:11:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv> (referer: http://www.rrys2019.com/resource/39714)
2020-03-25 22:11:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4813',
 'viewCount': '10392'}
2020-03-25 22:11:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv> (referer: http://www.rrys2019.com/resource/37366)
2020-03-25 22:11:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '72',
 'viewCount': '753537'}
2020-03-25 22:11:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv> (referer: http://www.rrys2019.com/resource/33190)
2020-03-25 22:11:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '38',
 'viewCount': '2433451'}
2020-03-25 22:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv> (referer: http://www.rrys2019.com/resource/39127)
2020-03-25 22:11:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '106',
 'viewCount': '7671'}
2020-03-25 22:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv> (referer: http://www.rrys2019.com/resource/39526)
2020-03-25 22:11:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '4113',
 'viewCount': '115310'}
2020-03-25 22:12:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv> (referer: http://www.rrys2019.com/resource/39693)
2020-03-25 22:12:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7571',
 'viewCount': '42786'}
2020-03-25 22:12:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv> (referer: http://www.rrys2019.com/resource/39654)
2020-03-25 22:12:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '1660',
 'viewCount': '53633'}
2020-03-25 22:12:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv> (referer: http://www.rrys2019.com/resource/38944)
2020-03-25 22:12:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4384',
 'viewCount': '19179'}
2020-03-25 22:12:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv> (referer: http://www.rrys2019.com/resource/39716)
2020-03-25 22:12:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '999999',
 'viewCount': '25720'}
2020-03-25 22:12:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv> (referer: http://www.rrys2019.com/resource/33701)
2020-03-25 22:12:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '9',
 'viewCount': '7031138'}
2020-03-25 22:12:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv> (referer: http://www.rrys2019.com/resource/35493)
2020-03-25 22:12:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '42',
 'viewCount': '1359781'}
2020-03-25 22:12:05 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 22:12:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8644,
 'downloader/request_count': 25,
 'downloader/request_method_count/GET': 25,
 'downloader/response_bytes': 172065,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'elapsed_time_seconds': 28.602521,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 14, 12, 5, 945030),
 'item_scraped_count': 12,
 'log_count/DEBUG': 37,
 'log_count/INFO': 10,
 'request_depth_max': 2,
 'response_received_count': 25,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2020, 3, 25, 14, 11, 37, 342509)}
2020-03-25 22:12:05 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 22:12:57 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 22:12:57 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 22:12:57 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 22:12:57 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like '
               'Gecko) Chrome/19.0.1061.0 Safari/536.3'}
2020-03-25 22:12:57 [scrapy.extensions.telnet] INFO: Telnet Password: a12114367acda46f
2020-03-25 22:12:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 22:12:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 22:12:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 22:12:57 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 22:12:57 [scrapy.core.engine] INFO: Spider opened
2020-03-25 22:12:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 22:12:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 22:12:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 22:12:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 22:12:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 42, in parse2
    print(s[1,-len(s)])
TypeError: string indices must be integers
2020-03-25 22:13:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 22:13:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 42, in parse2
    print(s[1,-len(s)])
TypeError: string indices must be integers
2020-03-25 22:13:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 22:13:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 42, in parse2
    print(s[1,-len(s)])
TypeError: string indices must be integers
2020-03-25 22:13:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 22:13:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 42, in parse2
    print(s[1,-len(s)])
TypeError: string indices must be integers
2020-03-25 22:13:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 22:13:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 42, in parse2
    print(s[1,-len(s)])
TypeError: string indices must be integers
2020-03-25 22:13:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 22:13:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 42, in parse2
    print(s[1,-len(s)])
TypeError: string indices must be integers
2020-03-25 22:13:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 22:13:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 42, in parse2
    print(s[1,-len(s)])
TypeError: string indices must be integers
2020-03-25 22:13:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 22:13:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 42, in parse2
    print(s[1,-len(s)])
TypeError: string indices must be integers
2020-03-25 22:13:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 22:13:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 42, in parse2
    print(s[1,-len(s)])
TypeError: string indices must be integers
2020-03-25 22:13:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 22:13:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 42, in parse2
    print(s[1,-len(s)])
TypeError: string indices must be integers
2020-03-25 22:13:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 22:13:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 42, in parse2
    print(s[1,-len(s)])
TypeError: string indices must be integers
2020-03-25 22:13:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 22:13:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
Traceback (most recent call last):
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "c:\programs\python\python38\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\programs\python\python38\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\学习\Python进阶训练营\mycode\rrys\rrys\spiders\rrys.py", line 42, in parse2
    print(s[1,-len(s)])
TypeError: string indices must be integers
2020-03-25 22:13:12 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 22:13:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4216,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 147008,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'elapsed_time_seconds': 15.064989,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 14, 13, 12, 968569),
 'log_count/DEBUG': 13,
 'log_count/ERROR': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 13,
 'scheduler/dequeued/memory': 13,
 'scheduler/enqueued': 13,
 'scheduler/enqueued/memory': 13,
 'spider_exceptions/TypeError': 12,
 'start_time': datetime.datetime(2020, 3, 25, 14, 12, 57, 903580)}
2020-03-25 22:13:12 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 22:13:30 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 22:13:30 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 22:13:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 22:13:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, '
               'like Gecko) Chrome/19.0.1055.1 Safari/535.24'}
2020-03-25 22:13:30 [scrapy.extensions.telnet] INFO: Telnet Password: 7c51e9b2c20576a4
2020-03-25 22:13:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 22:13:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 22:13:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 22:13:30 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 22:13:30 [scrapy.core.engine] INFO: Spider opened
2020-03-25 22:13:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 22:13:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 22:13:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 22:13:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 22:13:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 22:13:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 22:13:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 22:13:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 22:13:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 22:13:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 22:13:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 22:13:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 22:13:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 22:13:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 22:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 22:13:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv> (referer: http://www.rrys2019.com/resource/33190)
2020-03-25 22:13:46 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '38',
 'viewCount': '2433470'}
2020-03-25 22:13:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv> (referer: http://www.rrys2019.com/resource/39127)
2020-03-25 22:13:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '106',
 'viewCount': '7692'}
2020-03-25 22:13:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv> (referer: http://www.rrys2019.com/resource/39526)
2020-03-25 22:13:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '4113',
 'viewCount': '115319'}
2020-03-25 22:13:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv> (referer: http://www.rrys2019.com/resource/39693)
2020-03-25 22:13:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '7571',
 'viewCount': '42820'}
2020-03-25 22:13:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv> (referer: http://www.rrys2019.com/resource/39654)
2020-03-25 22:13:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/a-big-1.png',
 'score': '1660',
 'viewCount': '53643'}
2020-03-25 22:13:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv> (referer: http://www.rrys2019.com/resource/38944)
2020-03-25 22:13:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4384',
 'viewCount': '19266'}
2020-03-25 22:13:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv> (referer: http://www.rrys2019.com/resource/39716)
2020-03-25 22:13:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '999999',
 'viewCount': '25759'}
2020-03-25 22:13:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv> (referer: http://www.rrys2019.com/resource/33701)
2020-03-25 22:13:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/e-big-1.png',
 'score': '9',
 'viewCount': '7031198'}
2020-03-25 22:13:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv> (referer: http://www.rrys2019.com/resource/35493)
2020-03-25 22:13:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/b-big-1.png',
 'score': '42',
 'viewCount': '1359786'}
2020-03-25 22:13:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv> (referer: http://www.rrys2019.com/resource/39662)
2020-03-25 22:13:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '9709',
 'viewCount': '57234'}
2020-03-25 22:13:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv> (referer: http://www.rrys2019.com/resource/39714)
2020-03-25 22:13:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/c-big-1.png',
 'score': '4813',
 'viewCount': '10408'}
2020-03-25 22:14:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv> (referer: http://www.rrys2019.com/resource/37366)
2020-03-25 22:14:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv>
{'imgSrc': 'http://js.jstucdn.com/images/level-icon/d-big-1.png',
 'score': '72',
 'viewCount': '753557'}
2020-03-25 22:14:00 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 22:14:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8869,
 'downloader/request_count': 25,
 'downloader/request_method_count/GET': 25,
 'downloader/response_bytes': 172136,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'elapsed_time_seconds': 30.30073,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 14, 14, 0, 857485),
 'item_scraped_count': 12,
 'log_count/DEBUG': 37,
 'log_count/INFO': 10,
 'request_depth_max': 2,
 'response_received_count': 25,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2020, 3, 25, 14, 13, 30, 556755)}
2020-03-25 22:14:00 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 22:14:22 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 22:14:22 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 22:14:22 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 22:14:22 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, '
               'like Gecko) Chrome/19.0.1055.1 Safari/535.24'}
2020-03-25 22:14:22 [scrapy.extensions.telnet] INFO: Telnet Password: 03481220168a9d34
2020-03-25 22:14:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 22:14:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 22:14:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 22:14:23 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 22:14:23 [scrapy.core.engine] INFO: Spider opened
2020-03-25 22:14:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 22:14:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 22:14:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 22:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 22:14:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 22:14:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 22:14:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 22:14:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 22:14:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 22:14:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 22:14:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 22:14:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 22:14:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 22:14:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 22:14:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 22:14:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv> (referer: http://www.rrys2019.com/resource/39714)
2020-03-25 22:14:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv>
{'imgSrc': 'c', 'score': '4813', 'viewCount': '10408'}
2020-03-25 22:14:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv> (referer: http://www.rrys2019.com/resource/37366)
2020-03-25 22:14:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv>
{'imgSrc': 'd', 'score': '72', 'viewCount': '753557'}
2020-03-25 22:14:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv> (referer: http://www.rrys2019.com/resource/33190)
2020-03-25 22:14:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv>
{'imgSrc': 'c', 'score': '38', 'viewCount': '2433476'}
2020-03-25 22:14:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv> (referer: http://www.rrys2019.com/resource/39127)
2020-03-25 22:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv>
{'imgSrc': 'a', 'score': '106', 'viewCount': '7692'}
2020-03-25 22:14:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv> (referer: http://www.rrys2019.com/resource/39526)
2020-03-25 22:14:44 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv>
{'imgSrc': 'd', 'score': '4113', 'viewCount': '115326'}
2020-03-25 22:14:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv> (referer: http://www.rrys2019.com/resource/39693)
2020-03-25 22:14:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv>
{'imgSrc': 'c', 'score': '7571', 'viewCount': '42840'}
2020-03-25 22:14:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv> (referer: http://www.rrys2019.com/resource/39654)
2020-03-25 22:14:45 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv>
{'imgSrc': 'a', 'score': '1660', 'viewCount': '53655'}
2020-03-25 22:14:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv> (referer: http://www.rrys2019.com/resource/38944)
2020-03-25 22:14:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv>
{'imgSrc': 'c', 'score': '4384', 'viewCount': '19266'}
2020-03-25 22:14:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv> (referer: http://www.rrys2019.com/resource/39716)
2020-03-25 22:14:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv>
{'imgSrc': 'c', 'score': '999999', 'viewCount': '25759'}
2020-03-25 22:14:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv> (referer: http://www.rrys2019.com/resource/33701)
2020-03-25 22:14:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv>
{'imgSrc': 'e', 'score': '9', 'viewCount': '7031198'}
2020-03-25 22:14:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv> (referer: http://www.rrys2019.com/resource/35493)
2020-03-25 22:14:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv>
{'imgSrc': 'b', 'score': '42', 'viewCount': '1359786'}
2020-03-25 22:14:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv> (referer: http://www.rrys2019.com/resource/39662)
2020-03-25 22:14:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv>
{'imgSrc': 'c', 'score': '9709', 'viewCount': '57234'}
2020-03-25 22:14:51 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 22:14:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8769,
 'downloader/request_count': 25,
 'downloader/request_method_count/GET': 25,
 'downloader/response_bytes': 172212,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'elapsed_time_seconds': 28.548534,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 14, 14, 51, 695618),
 'item_scraped_count': 12,
 'log_count/DEBUG': 37,
 'log_count/INFO': 10,
 'request_depth_max': 2,
 'response_received_count': 25,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2020, 3, 25, 14, 14, 23, 147084)}
2020-03-25 22:14:51 [scrapy.core.engine] INFO: Spider closed (finished)
2020-03-25 22:15:47 [scrapy.utils.log] INFO: Scrapy 2.0.0 started (bot: rrys)
2020-03-25 22:15:47 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.17763-SP0
2020-03-25 22:15:47 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-03-25 22:15:47 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'rrys',
 'DOWNLOAD_DELAY': 1,
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'rrys.spiders',
 'SPIDER_MODULES': ['rrys.spiders'],
 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)'}
2020-03-25 22:15:47 [scrapy.extensions.telnet] INFO: Telnet Password: 91516e9712fb6d48
2020-03-25 22:15:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-03-25 22:15:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-25 22:15:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-25 22:15:47 [scrapy.middleware] INFO: Enabled item pipelines:
['rrys.pipelines.RrysPipeline']
2020-03-25 22:15:47 [scrapy.core.engine] INFO: Spider opened
2020-03-25 22:15:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-25 22:15:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-03-25 22:15:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com> (referer: None)
2020-03-25 22:15:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33701> (referer: http://www.rrys2019.com)
2020-03-25 22:15:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/35493> (referer: http://www.rrys2019.com)
2020-03-25 22:15:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39662> (referer: http://www.rrys2019.com)
2020-03-25 22:15:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39714> (referer: http://www.rrys2019.com)
2020-03-25 22:15:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/37366> (referer: http://www.rrys2019.com)
2020-03-25 22:15:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/33190> (referer: http://www.rrys2019.com)
2020-03-25 22:15:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39127> (referer: http://www.rrys2019.com)
2020-03-25 22:15:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39526> (referer: http://www.rrys2019.com)
2020-03-25 22:15:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39693> (referer: http://www.rrys2019.com)
2020-03-25 22:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39654> (referer: http://www.rrys2019.com)
2020-03-25 22:16:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/38944> (referer: http://www.rrys2019.com)
2020-03-25 22:16:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/39716> (referer: http://www.rrys2019.com)
2020-03-25 22:16:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv> (referer: http://www.rrys2019.com/resource/33701)
2020-03-25 22:16:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33701/channel/tv>
{'imgSrc': 'e', 'score': '9', 'viewCount': '7031264'}
2020-03-25 22:16:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv> (referer: http://www.rrys2019.com/resource/35493)
2020-03-25 22:16:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/35493/channel/tv>
{'imgSrc': 'b', 'score': '42', 'viewCount': '1359791'}
2020-03-25 22:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv> (referer: http://www.rrys2019.com/resource/39662)
2020-03-25 22:16:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39662/channel/tv>
{'imgSrc': 'c', 'score': '9709', 'viewCount': '57243'}
2020-03-25 22:16:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv> (referer: http://www.rrys2019.com/resource/39714)
2020-03-25 22:16:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39714/channel/tv>
{'imgSrc': 'c', 'score': '4813', 'viewCount': '10415'}
2020-03-25 22:16:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv> (referer: http://www.rrys2019.com/resource/37366)
2020-03-25 22:16:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/37366/channel/tv>
{'imgSrc': 'd', 'score': '72', 'viewCount': '753565'}
2020-03-25 22:16:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv> (referer: http://www.rrys2019.com/resource/33190)
2020-03-25 22:16:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/33190/channel/tv>
{'imgSrc': 'c', 'score': '38', 'viewCount': '2433487'}
2020-03-25 22:16:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv> (referer: http://www.rrys2019.com/resource/39127)
2020-03-25 22:16:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39127/channel/tv>
{'imgSrc': 'a', 'score': '106', 'viewCount': '7709'}
2020-03-25 22:16:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv> (referer: http://www.rrys2019.com/resource/39526)
2020-03-25 22:16:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39526/channel/tv>
{'imgSrc': 'd', 'score': '4113', 'viewCount': '115339'}
2020-03-25 22:16:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv> (referer: http://www.rrys2019.com/resource/39693)
2020-03-25 22:16:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39693/channel/tv>
{'imgSrc': 'c', 'score': '7571', 'viewCount': '42860'}
2020-03-25 22:16:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv> (referer: http://www.rrys2019.com/resource/39654)
2020-03-25 22:16:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39654/channel/tv>
{'imgSrc': 'a', 'score': '1660', 'viewCount': '53670'}
2020-03-25 22:16:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv> (referer: http://www.rrys2019.com/resource/38944)
2020-03-25 22:16:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/38944/channel/tv>
{'imgSrc': 'c', 'score': '4384', 'viewCount': '19344'}
2020-03-25 22:16:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv> (referer: http://www.rrys2019.com/resource/39716)
2020-03-25 22:16:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.rrys2019.com/resource/index_json/rid/39716/channel/tv>
{'imgSrc': 'c', 'score': '999999', 'viewCount': '25813'}
2020-03-25 22:16:16 [scrapy.core.engine] INFO: Closing spider (finished)
2020-03-25 22:16:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7619,
 'downloader/request_count': 25,
 'downloader/request_method_count/GET': 25,
 'downloader/response_bytes': 171637,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'elapsed_time_seconds': 28.712348,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 3, 25, 14, 16, 16, 325962),
 'item_scraped_count': 12,
 'log_count/DEBUG': 37,
 'log_count/INFO': 10,
 'request_depth_max': 2,
 'response_received_count': 25,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2020, 3, 25, 14, 15, 47, 613614)}
2020-03-25 22:16:16 [scrapy.core.engine] INFO: Spider closed (finished)
